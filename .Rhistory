scale_y_continuous(expand = c(0.01, 0.01), breaks = seq(50, 85, by = 5)) +
labs(x = "GDP per capita, thousand US dollars (ln scale) ", y = "Life expectancy  (years)") +
theme_bg()
p5
p4 | p5
# running linear regression total GDP
reg3 <- lm(lifeexp ~ gdptot, data = xc)
summary(reg3)
# plotting LEVEL-LEVEL REGRESSION (total GDP)
p6 <- ggplot(
data = xc,
aes(x = gdptot, y = lifeexp)
) +
geom_point_da() +
geom_smooth_da(method = "lm") +
coord_cartesian(xlim = c(0, 24000), ylim = c(50, 85)) +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 24000), breaks = seq(0, 24000, by = 4000)) +
scale_y_continuous(expand = c(0.01, 0.01), limits = c(50, 85), breaks = seq(50, 85, by = 5)) +
labs(x = "Total GDP  (billion US dollars)", y = "Life expectancy  (years)") +
theme_bg()
p6
# running linear regression log total GDP
reg4 <- lm(lifeexp ~ lngdptot, data = xc)
summary(reg4)
# plotting LEVEL-LOG REGRESSION (total GDP)
p7 <- ggplot(
data = xc,
aes(x = gdptot, y = lifeexp)
) +
geom_point_da() +
geom_smooth_da(method = "lm") +
coord_cartesian(ylim = c(50, 85)) +
scale_x_continuous(trans = log_trans(), breaks = c(1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 10000)) +
scale_y_continuous(expand = c(0.01, 0.01), breaks = c(50, 55, 60, 65, 70, 75, 80, 85)) +
labs(x = "Total GDP (in ln scale))", y = "Life expectancy  (years)") +
theme_bg()
p7
# CASE STUDY: How is Life Expectancy Related to the Average Income of a Country?
# GPD PER CAPITA PIECEWISE LINEAR SPLINE
# setting the knot (GDP per capita over 50 000 dollars)
cutoff <- 50
# creating the log
cutoff_ln <- log(cutoff)
# running piecewise linear spline regression on log
reg5 <- lm(lifeexp ~ lspline::lspline(lngdppc, cutoff_ln), data = xc)
summary(reg5)
# running test of coefficients to check differences in slope for the different segments (5.5 vs -0.3)
lmtest::coeftest(reg5)
# calculating the residuals and creating a new variable
xc$e3 <- resid(reg5)
# calculating the predictions for the piecewise linear spline regression model
xc$sppred <- predict(lm(lifeexp ~ lspline::lspline(lngdppc, cutoff_ln), data = xc))
# plotting a scatterplot with the piecewise linear spline regression model
p1 <- ggplot(
data = xc,
aes(x = gdppc, y = lifeexp)
) +
geom_point_da() +
geom_line(data = xc, aes(x = gdppc, y = sppred), color = color[2], size = 0.7) +
geom_vline(xintercept = cutoff, color = color[3], size = 0.5, linetype = "dotted") +
coord_cartesian(ylim = c(50, 85)) +
scale_x_continuous(trans = log_trans(), breaks = c(0.1, 0.5, 1, 2, 5, 10, 20, 50, 100)) +
scale_y_continuous(expand = c(0.01, 0.01), breaks = seq(50, 85, by = 5)) +
labs(x = "GDP per capita, thousand US dollars (ln scale) ", y = "Life expectancy  (years)") +
theme_bg()
p1
# QUADRATIC IN LEVEL-LOG REGRESSION
# calculating the quadratic function
xc$lngdppc_sq <- xc$lngdppc^2
# running the polynomial (quadratic) linear regression
reg6 <- lm(lifeexp ~ lngdppc + lngdppc_sq, data = xc)
summary(reg6)
# calculating the residuals and creating a new variable
xc$e6 <- resid(reg6)
# plotting a scatterplot with the polynomial (quadratic) nonlinear regression (in scale)
p2 <- ggplot(data = xc, aes(x = gdppc, y = lifeexp)) +
geom_point_da() +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = color[2], se = F, size = 0.7) +
coord_cartesian(ylim = c(50, 85)) +
scale_x_continuous(trans = log_trans(), breaks = c(0.1, 0.5, 1, 2, 5, 10, 20, 50, 100)) +
scale_y_continuous(expand = c(0.01, 0.01), breaks = seq(50, 85, by = 5)) +
labs(x = "GDP per capita, thousand US dollars (ln scale) ", y = "Life expectancy  (years)") +
theme_bg()
p2
# plotting a scatterplot with the polynomial (quadratic) nonlinear regression (ln units)
p3 <- ggplot(data = xc, aes(x = lngdppc, y = lifeexp)) +
geom_point_da() +
geom_smooth(method = "lm", formula = y ~ poly(x, 2), color = color[2], se = F, size = 0.7) +
coord_cartesian(xlim = c(-1, 5), ylim = c(50, 90)) +
scale_x_continuous(breaks = seq(-1, 5, by = 0.5)) +
scale_y_continuous(breaks = seq(50, 90, by = 5)) +
labs(x = "ln(GDP per capita, thousand US dollars)", y = "Life expectancy  (years)") +
theme_bg()
p3
p1 | p2
# CASE STUDY: Regression and measurement erro in average customer ratings
# TAKE LOG PRICE
hotels$lnprice <- log(hotels$price)
# define cutoffs
k1 <- 100
k2 <- 200
# dividing data into three subsamples of roughly equal size
# <100
reg_me <- lm(lnprice ~ rating, data = subset(hotels, rating_count < k1))
summary(reg_me)
hotels$yhat <- predict(reg_me, hotels)
# >=100 < 200
reg_me2 <- lm(lnprice ~ rating, data = subset(hotels, rating_count >= k1 & rating_count < k2))
summary(reg_me2)
hotels$yhat2 <- predict(reg_me2, hotels)
# >200
reg_me3 <- lm(lnprice ~ rating, data = subset(hotels, rating_count >= k2))
summary(reg_me3)
hotels$yhat3 <- predict(reg_me3, hotels)
# plotting log hotel price and average customer ratings: samples with noisiness
p1 <- ggplot(data = hotels) +
geom_line(aes(x = rating, y = yhat, color = color[2]), size = 1) +
geom_line(aes(x = rating, y = yhat3, color = color[1]), size = 1) +
scale_color_manual(name = "", values = c(color[2], color[1]), labels = NULL, guide = "none") +
coord_cartesian(xlim = c(2, 5), ylim = c(3.5, 5)) +
expand_limits(x = 0.01, y = 0.01) +
scale_y_continuous(expand = c(0.01, 0.01)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(2, 5), breaks = seq(2, 5, by = 0.5)) +
labs(x = "Average rating", y = "ln(Hotel price, US dollars)") +
theme_bg() +
annotate("text", x = 2.6, y = 4.4, label = "More noisy: # of ratings<100", size = 2, color = color[2]) +
annotate("text", x = 3.1, y = 3.6, label = "Less noisy: # of ratings>200", size = 2, color = color[1])
p1
# CASE STUDY: How is Life Expectancy Related to the Average Income of a Country?
# running linear regression (unweighted)
reg7 <- lm(lifeexp ~ lngdppc, data = xc)
summary(reg7)
# running linear regression (weighted)
reg8 <- lm(lifeexp ~ lngdppc, data = xc, weights = population)
summary(reg8)
# plotting life expectancy and GDP per capita (unweighted)
p1 <- ggplot(data = xc, aes(x = gdppc, y = lifeexp)) +
geom_point_da(color = color[1], shape = 16, show.legend = F) +
geom_smooth(method = "lm", color = color[2], se = F, size = 0.7) +
scale_size(range = c(1, 15)) +
coord_cartesian(ylim = c(50, 85)) +
scale_x_continuous(trans = log_trans(), breaks = c(0.1, 0.5, 1, 2, 5, 10, 20, 50, 100)) +
scale_y_continuous(expand = c(0.01, 0.01), breaks = seq(50, 85, by = 5)) +
labs(x = "GDP per capita, thousand US dollars (ln scale) ", y = "Life expectancy  (years)") +
theme_bg()
p1
# plotting life expectancy and GDP per capita (weighted)
p2 <- ggplot(data = xc, aes(x = gdppc, y = lifeexp)) +
geom_point(data = xc, aes(size = population), color = color[1], shape = 16, alpha = 0.6, show.legend = F) +
geom_smooth(aes(weight = population), method = "lm", color = color[2], se = F, size = 0.7) +
scale_size(range = c(1, 15)) +
coord_cartesian(ylim = c(50, 85)) +
scale_x_continuous(trans = log_trans(), breaks = c(0.1, 0.5, 1, 2, 5, 10, 20, 50, 100)) +
scale_y_continuous(expand = c(0.01, 0.01), breaks = seq(50, 85, by = 5)) +
labs(x = "GDP per capita, thousand US dollars (ln scale) ", y = "Life expectancy  (years)") +
theme_bg() +
annotate("text", x = 70, y = 80, label = "USA", size = 2) +
annotate("text", x = 10, y = 82, label = "China", size = 2) +
annotate("text", x = 7, y = 63, label = "India", size = 2)
p2
# plotting life expectancy and log GDP per capita (unweighted)
p3 <- ggplot(data = xc, aes(x = lngdppc, y = lifeexp)) +
geom_point(data = xc, aes(size = population), color = color[1], shape = 16, alpha = 0.4, show.legend = F) +
geom_smooth(aes(weight = population), method = "lm", color = color[2], se = F, size = 0.7) +
scale_size(range = c(1, 15)) +
coord_cartesian(xlim = c(-1, 5), ylim = c(50, 90)) +
scale_x_continuous(breaks = seq(-1, 5, by = 0.5)) +
scale_y_continuous(breaks = seq(50, 90, by = 5)) +
labs(x = "ln(GDP per capita, thousand US dollars)", y = "Life expectancy  (years)", size = "Population") +
theme_bg()
p3
(p1 | p2) / (p2 | p3)
# plotting differences in slope estimates (unweighted vs weighted)
p4 <- ggplot(data = xc, aes(x = gdppc, y = lifeexp)) +
geom_smooth(method = "lm", color = color[2], se = F, size = 1) +
geom_smooth(aes(weight = population), method = "lm", color = color[3], se = F, size = 1) +
scale_size(range = c(1, 15)) +
coord_cartesian(ylim = c(50, 85)) +
scale_x_continuous(trans = log_trans(), breaks = c(0.1, 0.5, 1, 2, 5, 10, 20, 50, 100)) +
scale_y_continuous(expand = c(0.01, 0.01), breaks = seq(50, 85, by = 5)) +
labs(x = "GDP per capita, thousand US dollars (ln scale) ", y = "Life expectancy  (years)") +
theme_bg()
p4
# CASE STUDY – Estimating Gender and Age Differences in Earnings
# importing data
data_all <- read_csv("input/morg-2014-emp.csv",
col_types = cols(
.default = "?",
state = "c"
)
)
# (state must be as character: it's a mix of double and character in raw)
janitor::tabyl(data_all$state)
# filtering data
# keep only two occupation types: Market research analysts and marketing specialists and Computer and Mathematical Occupations
data_all <- data_all  |>  mutate(sample = ifelse(occ2012 == 0735, 1,
ifelse(data_all$occ2012 >= 1005 & data_all$occ2012 <= 1240, 2, 0)
))
#SET SAMPLE - Choose one of the occupations!
#Market research analysts and marketing specialists -1
#Computer and Mathematical Occupations-2
data <- data_all |>
filter(sample == 1 | sample == 2) |>
filter(sample == 1)
#gen female variable
#gen wage variables
data <- data |>
mutate(female = as.numeric(sex == 2)) |>
mutate(w = earnwke / uhours) |>
mutate(lnw = log(w)) |>
mutate(agesq = age^2)
# creating a new ds
# write_csv(data, "input/earnings_inference.csv")
#DISTRIBUTION OF EARNINGS
data |>
dplyr::select(earnwke, uhours, w) |>
summary()
data |>
filter(w >= 1) |>
dplyr::select(earnwke, uhours, w) |>
summary()
tabulate(data$female)
table(data$occ2012, data$female)
#linear regressions (female binary)
# plain SE
reg1 <- lm(lnw ~ female, data)
summary(reg1)
# with robust SE (female binary)
reg2 <- lm_robust(lnw ~ female, data = data, se_type = "HC1")
summary(reg2)
# comparing the two models
msummary(list(reg1, reg2),
fmt = "%.4f",
gof_omit = "DF|Deviance|Log.Lik.|F|R2 Adj.|AIC|BIC",
stars = c("*" = .05, "**" = .01)
)
# bootstrap
set.seed(201711)
# function to obtain regression weights
bs <- function(formula, data, indices) {
d <- data[indices, ] # allows boot to select sample
fit <- lm(formula, data = d)
return(coef(fit))
}
# bootstrapping with 1000 replications
results <- boot(
data = data, statistic = bs,
R = 1000, formula = lnw ~ female
)
b_earnings_female <- as.data.frame(results$t)
colnames(b_earnings_female) <- c("_b_intercept", "_b_female")
# plotting bootstrap distribution of the average female–male wage difference among market analysts
p1 <- ggplot(data = b_earnings_female, aes(`_b_female`)) +
geom_histogram(aes(y = (..count..) / sum(..count..)),
binwidth = 0.025, center = 0.0125, closed = "left",
color = color.outline, fill = color[1],
size = 0.2, alpha = 0.8, show.legend = F, na.rm = TRUE
) +
geom_segment(aes(x = -0.11, y = 0, xend = -0.11, yend = 0.2), colour = color[2], size = 1) +
annotate("text", x = -0.07, y = 0.18, label = "mean", size = 2.5) +
coord_cartesian(xlim = c(-0.3, 0.15), ylim = c(0, 0.2)) +
labs(x = "Slope coefficients from bootstrap samples", y = "Percent") +
scale_y_continuous(
expand = c(0.0, 0.0), limits = c(0, 0.2),
labels = scales::percent_format(accuracy = 1)
) +
theme_bg()
p1
# lintr::lint("main.Rmd", linters =
#               lintr::with_defaults(
#                 commented_code_linter = NULL,
#                 trailing_whitespace_linter = NULL
#                 )
#             )
# if you have additional scripts and want them to be linted too, add them here
# lintr::lint("scripts/my_script.R")
# calculating the se
se <- qnorm(0.95) * sd(nobs_df$nobs_1000) / sqrt(length(nobs_df$nobs_1000))
se
# calculating CI
left <- mean(nobs_df$nobs_1000) - se
right <- mean(nobs_df$nobs_1000) + se
c(left, right)
se
b_earnings_female
data.female <- b_earnings_female$_b_female
b_earnings_female[, 2]
data.female <- b_earnings_female[, 2]
head(data.female)
# calculating the se
se <- qnorm(0.95) * sd(data.female) / sqrt(length(data.female))
# calculating the se
se.female <- qnorm(0.95) * sd(data.female) / sqrt(length(data.female))
se.female
left <- mean(data.female) - se.female
right <- mean(data.female) + se.female
c(left, right)
# CASE STUDY: What Likelihood of Loss to Expect on a Stock Portfolio?
# Create 10 000 samples, with 500 and 1000 observations in each sample, taken from sp500
# remove first row as it has NA in pct_return
pct_return <- sp500  |>
dplyr::filter(!is.na(pct_return))  |>
dplyr::pull(pct_return)
# function for a specified number of samples: draws a specified number of observations from a vector, calculates the percentage of obs with greater than 5% losses
# 3 inputs: 'vector' is a vector of the source data, in this case pct_return. 'n_samples' is the number of samples we want to use.
# 'n_obs' is the number of observations in each sample
# output is a vector
create_samples <- function(vector, n_samples, n_obs) {
samples_pcloss <- c()
for (i in 1:n_samples) {
single_sample <- sample(vector, n_obs, replace = FALSE)
samples_pcloss[i] <- sum(single_sample < -5) / n_obs * 100
}
samples_pcloss
}
set.seed(123)
# creating samples
nobs_1000 <- create_samples(pct_return, 10000, 1000)
nobs_500 <- create_samples(pct_return, 10000, 500)
# converting results as tibble
nobs_df <- tibble(nobs_500,nobs_1000)
# calculating the se
se <- qnorm(0.95) * sd(nobs_df$nobs_1000) / sqrt(length(nobs_df$nobs_1000))
# calculating CI
left <- mean(nobs_df$nobs_1000) - se
right <- mean(nobs_df$nobs_1000) + se
# plotting simulated number of days with big losses
options(digits = 2)
p2 <- ggplot(nobs_df, aes(nobs_1000)) +
geom_histogram(binwidth = 0.1, color = color.outline, fill = color[1], alpha = 0.8, boundary = 0, closed = "left") +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
geom_vline(aes(xintercept = mean(nobs_1000)), color = color[2], size = 0.7) +
coord_cartesian(xlim = c(0, 1.5), ylim = c(0, 2500)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.5), breaks = seq(0, 1.5, by = 0.25)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 2500), breaks = seq(0, 2500, by = 500)) +
geom_segment(aes(x = 0.8, y = 2000, xend = 0.53, yend = 2000), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 0.85, y = 2000, label = "Mean", size = 2.5) +
theme_bg()
p2
# comparing density for both simulations
p3 <- ggplot(nobs_df, aes(nobs_1000)) +
stat_density(geom = "line", aes(color = "n1000"), bw = 0.45, size = 1, kernel = "epanechnikov") +
stat_density(geom = "line", aes(nobs_500, color = "n500"), bw = 0.45, linetype = "twodash", size = 1, kernel = "epanechnikov") +
labs(x = "Percent of days with losses over 5%", y = "Density") +
geom_vline(xintercept = 0.5, colour = color[3], size = 0.7, linetype = "dashed") +
geom_segment(aes(x = 0.9, y = 0.72, xend = 0.65, yend = 0.72), size = 0.5, arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 1.1, y = 0.72, label = "Larger sample", size = 2) +
geom_segment(aes(x = 0.9, y = 0.68, xend = 0.65, yend = 0.68), size = 0.5, arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 1.1, y = 0.68, label = "Smaller sample", size = 2) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.5), breaks = seq(0, 1.5, by = 0.25)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.8), breaks = seq(0, 0.8, by = 0.2)) +
scale_color_manual(name = "", values = c(n1000 = color[1], n500 = color[2])) +
theme_bg() +
theme(legend.position = "none")
p3
# plotting histogram of big loss simulations with N = 500 and N = 1000
p4 <- ggplot(data = nobs_df) +
geom_histogram(aes(x = nobs_500, y = (..count..) / sum(..count..) * 100, color = "n500", fill = "n500"), binwidth = 0.2, boundary = 0, closed = "left", alpha = 0.7) +
geom_histogram(aes(x = nobs_1000, y = (..count..) / sum(..count..) * 100, color = "n1000", fill = "n1000"), binwidth = 0.2, boundary = 0, closed = "left", alpha = 0.1, size = 0.7) +
ylab("Percent") +
xlab("Percent of days with losses over 5%") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.6), breaks = seq(0, 1.6, by = 0.2)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 50)) +
scale_color_manual(name = "", values = c(color[2], color[1])) +
scale_fill_manual(name = "", values = c(color[2], color[1])) +
theme_bg() +
theme(
legend.position = c(0.7, 0.9),
legend.key.size = unit(x = 0.4, units = "cm"),
legend.direction = "horizontal"
)
p4
# looking at distribution in a table
janitor::tabyl(nobs_df$nobs_500, sort = TRUE)
janitor::tabyl(nobs_df$nobs_1000, sort = TRUE)
# CASE STUDY: What Likelihood of Loss to Expect on a Stock Portfolio?
set.seed(573164)
M <- 10000
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
Results <- as_tibble(Results)
names(Results) <- c(
"loss1", "loss2", "loss3", "loss4", "loss5", "loss6",
"loss7", "loss8", "loss9", "loss10"
)
p1 <- ggplot(Results, aes(loss5)) +
geom_histogram_da(type = "frequency", binwidth = 0.04, boundary = 0, closed = "left") +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1200), breaks = seq(0, 1200, 200)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.2), breaks = seq(0, 1.2, 0.1)) +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
theme_bg()
p1
head(Results)
sd(Results)
boot.ci(Results)
boot.ci(Results, type = "norm")
mean(Results)
boot.ci(Results$loss1, type = "norm")
str(Results)
ncol(Results$loss1)
ncol(Results$loss2)
nrow(Results$loss2)
boot.ci(Results$loss5)
Results$loss5
boot.ci(Results$loss5, conf = "normal")
set.seed(573164)
M <- 10000
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
str(Results+)
str(Results)
boot.ci(Results[,4], conf = "normal"  )
help("boot.ci")
boot.ci(Results$loss5, conf = .95, type = "normal")
# CASE STUDY: What Likelihood of Loss to Expect on a Stock Portfolio?
set.seed(573164)
M <- 10000
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
Results <- as_tibble(Results)
names(Results) <- c(
"loss1", "loss2", "loss3", "loss4", "loss5", "loss6",
"loss7", "loss8", "loss9", "loss10"
)
p1 <- ggplot(Results, aes(loss5)) +
geom_histogram_da(type = "frequency", binwidth = 0.04, boundary = 0, closed = "left") +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1200), breaks = seq(0, 1200, 200)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.2), breaks = seq(0, 1.2, 0.1)) +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
theme_bg()
p1
se <- qnorm(0.95) * sd(Results$loss5) / sqrt(length(Results$loss5))
se
left <- mean(Results$loss5) - se
right <- mean(Results$loss5) + se
c(left, right)
# calculating the se
se <- qt(0.95) * sd(Results$loss5) / sqrt(length(Results$loss5))
se <- qt(0.95) * sd(Results$loss5) / sqrt(length(Results$loss5))
# calculating the se
se <- qt(p = 0.95, df = N - 1) * sd(Results$loss5) / sqrt(length(Results$loss5))
# calculating the se
se <- qt(p = 0.95, df = length((Results$loss5)) - 1) * sd(Results$loss5) / sqrt(length(Results$loss5))
se
left <- mean(Results$loss5) - se
right <- mean(Results$loss5) + se
c(left, right)
# CASE STUDY: What Likelihood of Loss to Expect on a Stock Portfolio?
set.seed(573164)
M <- 10000
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
Results <- as_tibble(Results)
names(Results) <- c(
"loss1", "loss2", "loss3", "loss4", "loss5", "loss6",
"loss7", "loss8", "loss9", "loss10"
)
p1 <- ggplot(Results, aes(loss5)) +
geom_histogram_da(type = "frequency", binwidth = 0.04, boundary = 0, closed = "left") +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1200), breaks = seq(0, 1200, 200)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.2), breaks = seq(0, 1.2, 0.1)) +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
theme_bg()
p1
# CASE STUDY: What Likelihood of Loss to Expect on a Stock Portfolio?
set.seed(573164)
M <- 10000
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
Results <- as_tibble(Results)
names(Results) <- c(
"loss1", "loss2", "loss3", "loss4", "loss5", "loss6",
"loss7", "loss8", "loss9", "loss10"
)
p1 <- ggplot(Results, aes(loss5)) +
geom_histogram_da(type = "frequency", binwidth = 0.04, boundary = 0, closed = "left") +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1200), breaks = seq(0, 1200, 200)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.2), breaks = seq(0, 1.2, 0.1)) +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
theme_bg()
p1
