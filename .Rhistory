# adding new variable for plotting
top_managers <- top_managers |>
dplyr::mutate(fill = case_when(
manager_games < 18 ~ "1",
manager_games > 18 ~ "0"
))
# plotting the results
p1 <- top_managers |>
ggplot(aes(x = reorder(manager_name, manager_avg_points), y = manager_avg_points, fill = fill, alpha = fill)) +
geom_col(show.legend = F) +
ylab("Average points per game") +
xlab("Manager name") +
scale_fill_manual(values = c(color[1], color[4])) +
scale_alpha_manual(values = c(0.8, 0.3)) +
scale_y_continuous(expand = c(0.01, 0.01), limits = c(0, 3), breaks = seq(0, 3, 0.3)) +
coord_flip() +
theme_bg() +
cowplot::background_grid(major = "x", minor = "none")
p1
# load data
vienna <- read_csv("input/hotels-vienna.csv")
# looking at the frequencies of all types of accommodation
table(vienna$accommodation_type)
# filtering accommodation: Hotel
vienna_hotels <- vienna |>
dplyr::filter(accommodation_type == "Hotel")
# plotting distributions
# Absolute frequency (count)
p1 <- ggplot(data = vienna_hotels, aes(x = stars)) +
geom_bar(color = color.outline, fill = color[1], alpha = 0.8, na.rm = T) +
geom_text(stat = "count", aes(label = ..count..), vjust = -0.5, size = 2.5) +
labs(x = "Star rating (N. stars)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0.5, 5.5), breaks = seq(1, 5, 0.5)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 140), breaks = seq(0, 140, 20)) +
theme_bg()
# Relative frequency (percent)
p2 <- ggplot(data = vienna_hotels, aes(x = stars, y = (..count..) / sum(..count..))) +
geom_bar(color = color.outline, fill = color[1], alpha = 0.8, na.rm = T) +
geom_text(stat = "count", aes(label = round((..count..) / sum(..count..) * 100, 1)), vjust = -0.5, size = 2.5) +
labs(x = "Star rating (N. stars)", y = "Percent") +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0.5, 5.5), breaks = seq(1, 5, 0.5)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.5), breaks = seq(0, 0.5, 0.1), labels = scales::percent_format(accuracy = 1)) +
theme_bg()
p1|p2
# filtering 3-4 stars, without 1000 euro extreme value
vienna_hotels <- vienna |>
dplyr::filter(accommodation_type == "Hotel") |>
dplyr::filter(stars >= 3 & stars <= 4) |>
dplyr::filter(!is.na(stars)) |>
dplyr::filter(price <= 1000)
table(vienna_hotels$city)
table(vienna_hotels$stars)
# plotting hotel price (different bindwidth)
p3 <- ggplot(data = vienna_hotels, aes(x = price)) +
geom_histogram_da(type = "frequency", binwidth = 10) +
labs(x = "Price (US dollars)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
coord_cartesian(clip = "off") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 50)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 40), breaks = seq(0, 40, by = 5)) +
theme_bg()
p4 <- ggplot(data = vienna_hotels, aes(x = price)) +
geom_histogram_da(type = "frequency", binwidth = 40) +
labs(x = "Price (US dollars)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
coord_cartesian(clip = "off") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 50)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 40), breaks = seq(0, 40, by = 5)) +
theme_bg()
p5 <- ggplot(data = vienna_hotels, aes(x = price)) +
geom_histogram_da(type = "frequency", binwidth = 80) +
labs(x = "Price (US dollars)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
coord_cartesian(clip = "off") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 50)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 40), breaks = seq(0, 40, by = 5)) +
theme_bg()
p6 <- ggplot(data = vienna_hotels, aes(x = price)) +
geom_histogram_da(type = "frequency", binwidth = 20) +
labs(x = "Price (US dollars)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
coord_cartesian(clip = "off") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 50)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 40), breaks = seq(0, 40, by = 5)) +
theme_bg()
(p3 | p4 | p5) / p6
# plotting distance
p7 <- ggplot(data = vienna_hotels, aes(x = distance)) +
geom_histogram_da(type = "frequency", binwidth = 0.5) +
labs(x = "Distance to city center (miles)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 14), breaks = seq(0, 14, by = 2)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 61), breaks = seq(0, 60, by = 10)) +
geom_segment(aes(x = 8.2, y = 0, xend = 8.2, yend = 60), color = color[2], size = 1) +
# geom_segment(aes(x = 10, y = 40, xend = 8.4, yend = 40), arrow = arrow(length = unit(0.2, "cm")))+
annotate("text", x = 11, y = 29, label = "Too far out", size = 2) +
annotate("rect", xmin = 8.2, xmax = 14, ymin = 0, ymax = 60, fill = color[4], alpha = 0.1) +
theme_bg()
p7
# looking at the actual place of hotels (included outside the city of Vienna)
table(vienna_hotels$city_actual)
# filtering 3-4 stars, less than 8miles from center, without 1000 euro extreme value
vienna_hotels <- vienna |>
dplyr::filter(accommodation_type == "Hotel") |>
dplyr::filter(stars >= 3 & stars <= 4) |>
dplyr::filter(!is.na(stars)) |>
dplyr::filter(price <= 1000) |>
dplyr::filter(city_actual == "Vienna")
# CASE STUDY: Comparing Hotel Prices in Europe: Vienna vs London
# load data
hotels_europe_price <- read_csv("input/hotels-europe_price.csv")
hotels_europe_features <- read_csv("input/hotels-europe_features.csv")
# creating a working data table for analysis
hotels_europe <- dplyr::left_join(hotels_europe_price, hotels_europe_features, by = "hotel_id")
# filtering for same Vienna data we used + London same date
hotels_europe_london_viena <- hotels_europe |>
dplyr::filter(year == 2017 & month == 11 & weekend == 0) |>
dplyr::filter(city %in% c("Vienna", "London")) |>
dplyr::filter(accommodation_type == "Hotel") |>
dplyr::filter(stars >= 3 & stars <= 4) |>
dplyr::filter(!is.na(stars)) |>
dplyr::filter(city_actual %in% c("Vienna", "London")) |>
dplyr::filter(price <= 600)
# looking at the mean price for both cities
hotels_europe_london_viena |>
dplyr::group_by(city) |>
dplyr::summarise(mean_price = mean(price), max = max(price), n = n())
# plotting the distribution of hotel price
p1 <- ggplot(data = filter(hotels_europe_london_viena, city == "Vienna"), aes(x = price)) +
geom_histogram_da(type = "percent", binwidth = 20) +
labs(x = "Price (US dollars)", y = "Percent", title = "Vienna") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 100)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.3), breaks = seq(0, 0.3, by = 0.1), labels = scales::percent_format()) +
theme_bg()
p2 <- ggplot(data = filter(hotels_europe_london_viena, city == "London"), aes(x = price)) +
geom_histogram_da(type = "percent", binwidth = 20) +
labs(x = "Price (US dollars)", y = "Percent", title = "London") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 100)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.3), breaks = seq(0, 0.3, by = 0.1), labels = scales::percent_format()) +
theme_bg()
(p1 | p2)
# plotting same data using density plot
p3 <- ggplot(data = hotels_europe_london_viena, aes(x = price, y = stat(density), color = city)) +
geom_line(stat = "density", show.legend = F, na.rm = TRUE) +
labs(x = "Price (US dollars)", y = "Density", color = "") +
scale_color_manual(
name = "",
values = c(color[2], color[1]),
labels = c("London", "Vienna")
) +
scale_y_continuous(expand = c(0.0, 0.0), limits = c(0, 0.015), breaks = seq(0, 0.015, by = 0.003)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 100)) +
geom_text(aes(x = 340, y = 0.0026, label = "London"), color = color[2], size = 2.5) +
geom_text(aes(x = 170, y = 0.008, label = "Vienna"), color = color[1], size = 2.5) +
theme_bg()
p3
# summarizing all statistics in one table
hotels_europe_london_viena_tab <- hotels_europe_london_viena |>
dplyr::group_by(city) |>
dplyr::summarise(
n = length(price), mean = mean(price), median = median(price), min = min(price), max = max(price),
sd = sd(price), skew = ((mean(price) - median(price)) / sd(price))
)
hotels_europe_london_viena_tab
# CASE STUDY: Measuring Home Team Advantage in Football
# load data
games <- read_csv("input/epl_games.csv")
# looking at 2016/17 season only
games <- subset(games, season == 2016)
# adding a goal difference variable
games <- games |>
dplyr::mutate(home_goaladv = goals_home - goals_away)
# summary statistics
summary(games$home_goaladv)
psych::describe(games$home_goaladv)
# plotting the distribution of the goal difference variable
p1 <- ggplot(data = games, aes(x = home_goaladv, y = (..count..) / sum(..count..))) +
geom_histogram(
color = color.outline, fill = theme_colors[1],
size = 0.2, alpha = 0.8, show.legend = F, na.rm = TRUE,
binwidth = 1
) +
geom_text(stat = "count", aes(label = round((..count..) / sum(..count..) * 100, 1)), hjust = 0.5, vjust = -0.5, size = 2) +
labs(x = "Goal difference", y = "Share of games (percent)") +
scale_x_continuous(expand = c(0.05, 0.05), limits = c(-6, 6), breaks = seq(-6, 6, by = 1)) +
scale_y_continuous(expand = c(0, 0), limits = c(0, 0.25), breaks = seq(0, 0.25, by = 0.05), labels = scales::percent_format(accuracy = 5L)) +
theme_bg()
p1
reticulate::repl_python()
# We calculated the mean, the standard deviation of the goal difference and the relative frequency of games
# Check the main descriptives
datasummary(diff ~ Mean + SD + Min + Max + Median + Max, data = pd)
# Check the main descriptives
modelsummary::datasummary(diff ~ Mean + SD + Min + Max + Median + Max, data = pd)
# Check the main descriptives
x <- modelsummary::datasummary(diff ~ Mean + SD + Min + Max + Median + Max, data = pd)
x
styler:::style_selection()
p1 <- ggplot(data = pd, aes(diff)) +
geom_histogram(
binwidth = 5, boundary = 0, closed = "left",
fill = color[1], size = 0.25, alpha = 0.8, show.legend = F, na.rm = TRUE
) +
labs(x = "Online - offline price difference (US dollars)", y = "Frequency") +
theme_bg() +
scale_x_continuous(limits = c(-420, 420), breaks = seq(-400, 420, by = 100)) +
scale_y_continuous(limits = c(0, 6000), breaks = seq(0, 6000, by = 1000), expand = c(0.01, 0.01)) +
geom_segment(aes(x = 300, y = 500, xend = 415, yend = 20), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 300, y = 700, label = "max value= 415", size = 2.5) +
geom_segment(aes(x = -280, y = 500, xend = -380, yend = 20), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = -300, y = 700, label = "min value= -380", size = 2.5)
p1
styler:::style_selection()
# 4.99999 not 5 -- needed because of data imported from stata may be stored wierdly.
pd1 <- subset(pd, abs(pd$diff) < 4.999999)
Hmisc::describe(pd1$diff)
hist2 <- ggplot(data = pd, aes(diff)) +
geom_histogram(
binwidth = 0.5, boundary = -0, closed = "left",
color = color.outline, fill = color[1], size = 0.25, alpha = 0.8, show.legend = F, na.rm = TRUE
) +
labs(x = "Online - offline price difference (US dollars)", y = "Frequency") +
theme_bg() +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(limits = c(-5, 5), breaks = seq(-5, 5, by = 1)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 5000), breaks = seq(0, 5000, by = 1000))
hist2
p2 <- ggplot(data = pd, aes(diff)) +
geom_histogram(
binwidth = 0.5, boundary = -0, closed = "left",
color = color.outline, fill = color[1], size = 0.25, alpha = 0.8, show.legend = F, na.rm = TRUE
) +
labs(x = "Online - offline price difference (US dollars)", y = "Frequency") +
theme_bg() +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(limits = c(-5, 5), breaks = seq(-5, 5, by = 1)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 5000), breaks = seq(0, 5000, by = 1000))
p2
Hmisc::describe(pd1$diff)
# load data
pd <- read.csv(paste0("input/online_offline_ALL_clean.csv"))
# filter the data
pd <- pd |>
filter(COUNTRY == "USA") |>
filter(PRICETYPE == "Regular Price") |>
filter(is.na(sale_online)) |>
filter(!is.na(price)) |>
filter(!is.na(price_online))
# drop errors (+1000 dollars)
pd <- pd |> filter(price < 1000)
# creating diff variable
pd <- pd |> mutate(diff = price_online - price)
# Check the main descriptives
modelsummary::datasummary(diff ~ Mean + SD + Min + Max + Median + Max, data = pd)
# plotting online-offline price differences
p1 <- ggplot(data = pd, aes(diff)) +
geom_histogram(
binwidth = 5, boundary = 0, closed = "left",
fill = color[1], size = 0.25, alpha = 0.8, show.legend = F, na.rm = TRUE
) +
labs(x = "Online - offline price difference (US dollars)", y = "Frequency") +
theme_bg() +
scale_x_continuous(limits = c(-420, 420), breaks = seq(-400, 420, by = 100)) +
scale_y_continuous(limits = c(0, 6000), breaks = seq(0, 6000, by = 1000), expand = c(0.01, 0.01)) +
geom_segment(aes(x = 300, y = 500, xend = 415, yend = 20), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 300, y = 700, label = "max value= 415", size = 2.5) +
geom_segment(aes(x = -280, y = 500, xend = -380, yend = 20), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = -300, y = 700, label = "min value= -380", size = 2.5)
p1
# 4.99999 not 5 -- needed because of data imported from stata may be stored wierdly.
# pd1 <- subset(pd, abs(pd$diff) < 4.999999)
# Hmisc::describe(pd1$diff)
# plotting online-offline price differences (+-5 dollar price difference)
p2 <- ggplot(data = pd, aes(diff)) +
geom_histogram(
binwidth = 0.5, boundary = -0, closed = "left",
color = color.outline, fill = color[1], size = 0.25, alpha = 0.8, show.legend = F, na.rm = TRUE
) +
labs(x = "Online - offline price difference (US dollars)", y = "Frequency") +
theme_bg() +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(limits = c(-5, 5), breaks = seq(-5, 5, by = 1)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 5000), breaks = seq(0, 5000, by = 1000))
p2
p1 | p2
# load data
pd <- read.csv(paste0("input/online_offline_ALL_clean.csv"))
# filter the data
pd <- pd |>
filter(COUNTRY == "USA") |>
filter(PRICETYPE == "Regular Price") |>
filter(is.na(sale_online)) |>
filter(!is.na(price)) |>
filter(!is.na(price_online))
# drop errors (+1000 dollars)
pd <- pd |> filter(price < 1000)
# creating diff variable
pd <- pd |> mutate(diff = price_online - price)
# Check the main descriptives
modelsummary::datasummary(diff ~ Mean + SD + Min + Max + Median + Max, data = pd)
# plotting online-offline price differences
p1 <- ggplot(data = pd, aes(diff)) +
geom_histogram(
binwidth = 5, boundary = 0, closed = "left",
fill = color[1], size = 0.25, alpha = 0.8, show.legend = F, na.rm = TRUE
) +
labs(x = "Online - offline price difference (US dollars)", y = "Frequency") +
theme_bg() +
scale_x_continuous(limits = c(-420, 420), breaks = seq(-400, 420, by = 100)) +
scale_y_continuous(limits = c(0, 6000), breaks = seq(0, 6000, by = 1000), expand = c(0.01, 0.01)) +
geom_segment(aes(x = 300, y = 500, xend = 415, yend = 20), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 300, y = 700, label = "max value= 415", size = 2.5) +
geom_segment(aes(x = -280, y = 500, xend = -380, yend = 20), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = -300, y = 700, label = "min value= -380", size = 2.5)
p1
# 4.99999 not 5 -- needed because of data imported from stata may be stored wierdly.
# pd1 <- subset(pd, abs(pd$diff) < 4.999999)
# Hmisc::describe(pd1$diff)
# plotting online-offline price differences (+-5 dollar price difference)
p2 <- ggplot(data = pd, aes(diff)) +
geom_histogram(
binwidth = 0.5, boundary = -0, closed = "left",
color = color.outline, fill = color[1], size = 0.25, alpha = 0.8, show.legend = F, na.rm = TRUE
) +
labs(x = "Online - offline price difference (US dollars)", y = "Frequency") +
theme_bg() +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(limits = c(-5, 5), breaks = seq(-5, 5, by = 1)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 5000), breaks = seq(0, 5000, by = 1000))
p2
p1 | p2
datasummary_skim(pd)
datasummary_skim(pd$price)
datasummary(pd)
# Check the main descriptives
modelsummary::datasummary(diff ~ Mean + SD + Min + Max + Median + Max, data = pd)
modelsummary::datasummary(diff ~ Mean + SD + Min + Max + Median + Max, data = pd)
# CASE STUDY: What likelihood of loss to expect on a stock portfolio
# load data
sp500 <- read_csv("input/SP500_2006_16_data.csv", na = c("", "#N/A"))
# subsetting all the values that are NOT NAs
sp500 <- subset(sp500, VALUE != "NA")
# creating percent return
sp500 <- sp500 |>
dplyr::mutate(pct_return = (VALUE - dplyr::lag(VALUE)) / dplyr::lag(VALUE) * 100)
# creating date variable
sp500$year <- format(sp500$DATE, "%Y")
sp500$month <- format(sp500$DATE, "%m")
sp500$year <- as.numeric(sp500$year)
sp500$month <- as.numeric(sp500$month)
sp500$yearmonth <- sp500$year * 100 + sp500$month
# plotting daily returns
p1 <- ggplot(sp500, aes(pct_return)) +
geom_histogram_da(binwidth = 0.25, type = "frequency") +
geom_vline(xintercept = -5, size = 0.7, color = color[2]) +
labs(x = "Daily return (percent)", y = "Frequency") +
coord_cartesian(xlim = c(-10, 10), ylim = c(0, 400)) +
scale_y_continuous(expand = c(0, 0)) +
geom_segment(aes(x = -6, y = 220, xend = -5, yend = 220), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = -8, y = 220, label = "5% loss", size = 2.5) +
theme_bg()
p1
# Create 10 000 samples, with 500 and 1000 observations in each sample, taken from sp500
# remove first row as it has NA in pct_return
pct_return <- sp500  |>
dplyr::filter(!is.na(pct_return))  |>
dplyr::pull(pct_return)
# function for a specified number of samples: draws a specified number of observations from a vector, calculates the percentage of obs with greater than 5% losses
# 3 inputs: 'vector' is a vector of the source data, in this case pct_return. 'n_samples' is the number of samples we want to use.
# 'n_obs' is the number of observations in each sample
# output is a vector
create_samples <- function(vector, n_samples, n_obs) {
samples_pcloss <- c()
for (i in 1:n_samples) {
single_sample <- sample(vector, n_obs, replace = FALSE)
samples_pcloss[i] <- sum(single_sample < -5) / n_obs * 100
}
samples_pcloss
}
set.seed(123)
# creating samples
nobs_1000 <- create_samples(pct_return, 10000, 1000)
nobs_500 <- create_samples(pct_return, 10000, 500)
# converting results as tibble
nobs_df <- tibble(nobs_500,nobs_1000)
# calculating the se
se <- qnorm(0.95) * sd(nobs_df$nobs_1000) / sqrt(length(nobs_df$nobs_1000))
# calculating CI
left <- mean(nobs_df$nobs_1000) - se
right <- mean(nobs_df$nobs_1000) + se
# plotting simulated number of days with big losses
options(digits = 2)
p2 <- ggplot(nobs_df, aes(nobs_1000)) +
geom_histogram(binwidth = 0.1, color = color.outline, fill = color[1], alpha = 0.8, boundary = 0, closed = "left") +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
geom_vline(aes(xintercept = mean(nobs_1000)), color = color[2], size = 0.7) +
coord_cartesian(xlim = c(0, 1.5), ylim = c(0, 2500)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.5), breaks = seq(0, 1.5, by = 0.25)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 2500), breaks = seq(0, 2500, by = 500)) +
geom_segment(aes(x = 0.8, y = 2000, xend = 0.53, yend = 2000), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 0.85, y = 2000, label = "Mean", size = 2.5) +
theme_bg()
p2
# comparing density for both simulations
p3 <- ggplot(nobs_df, aes(nobs_1000)) +
stat_density(geom = "line", aes(color = "n1000"), bw = 0.45, size = 1, kernel = "epanechnikov") +
stat_density(geom = "line", aes(nobs_500, color = "n500"), bw = 0.45, linetype = "twodash", size = 1, kernel = "epanechnikov") +
labs(x = "Percent of days with losses over 5%", y = "Density") +
geom_vline(xintercept = 0.5, colour = color[3], size = 0.7, linetype = "dashed") +
geom_segment(aes(x = 0.9, y = 0.72, xend = 0.65, yend = 0.72), size = 0.5, arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 1.1, y = 0.72, label = "Larger sample", size = 2) +
geom_segment(aes(x = 0.9, y = 0.68, xend = 0.65, yend = 0.68), size = 0.5, arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 1.1, y = 0.68, label = "Smaller sample", size = 2) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.5), breaks = seq(0, 1.5, by = 0.25)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.8), breaks = seq(0, 0.8, by = 0.2)) +
scale_color_manual(name = "", values = c(n1000 = color[1], n500 = color[2])) +
theme_bg() +
theme(legend.position = "none")
p3
# plotting histogram of big loss simulations with N = 500 and N = 1000
p4 <- ggplot(data = nobs_df) +
geom_histogram(aes(x = nobs_500, y = (..count..) / sum(..count..) * 100, color = "n500", fill = "n500"), binwidth = 0.2, boundary = 0, closed = "left", alpha = 0.7) +
geom_histogram(aes(x = nobs_1000, y = (..count..) / sum(..count..) * 100, color = "n1000", fill = "n1000"), binwidth = 0.2, boundary = 0, closed = "left", alpha = 0.1, size = 0.7) +
ylab("Percent") +
xlab("Percent of days with losses over 5%") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.6), breaks = seq(0, 1.6, by = 0.2)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 50)) +
scale_color_manual(name = "", values = c(color[2], color[1])) +
scale_fill_manual(name = "", values = c(color[2], color[1])) +
theme_bg() +
theme(
legend.position = c(0.7, 0.9),
legend.key.size = unit(x = 0.4, units = "cm"),
legend.direction = "horizontal"
)
p4
# looking at distribution in a table
janitor::tabyl(nobs_df$nobs_500, sort = TRUE)
janitor::tabyl(nobs_df$nobs_1000, sort = TRUE)
set.seed(573164)
M <- 10000
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
Results <- as_tibble(Results)
names(Results) <- c(
"loss1", "loss2", "loss3", "loss4", "loss5", "loss6",
"loss7", "loss8", "loss9", "loss10"
)
p1 <- ggplot(Results, aes(loss5)) +
geom_histogram_da(type = "frequency", binwidth = 0.04, boundary = 0, closed = "left") +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1200), breaks = seq(0, 1200, 200)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.2), breaks = seq(0, 1.2, 0.1)) +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
theme_bg()
p1
# CASE STUDY: Comparing Online and Offline Prices: Testing the Difference
pd <- read.csv("input/online_offline_ALL_clean.csv")
# filter the data
pd <- pd |>
filter(COUNTRY == "USA") |>
filter(PRICETYPE == "Regular Price") |>
filter(is.na(sale_online)) |>
filter(!is.na(price)) |>
filter(!is.na(price_online))
# drop errors (+1000 dollars)
pd <- pd |> filter(price < 1000)
# creating diff variable
pd <- pd |> mutate(diff = price_online - price)
# Check the main descriptives
modelsummary::datasummary(diff ~ Mean + SD + Min + Max + Median + Max, data = pd)
# plotting online-offline price differences
p1 <- ggplot(data = pd, aes(diff)) +
geom_histogram(
binwidth = 5, boundary = 0, closed = "left",
fill = color[1], size = 0.25, alpha = 0.8, show.legend = F, na.rm = TRUE
) +
labs(x = "Online - offline price difference (US dollars)", y = "Frequency") +
theme_bg() +
scale_x_continuous(limits = c(-420, 420), breaks = seq(-400, 420, by = 100)) +
scale_y_continuous(limits = c(0, 6000), breaks = seq(0, 6000, by = 1000), expand = c(0.01, 0.01)) +
geom_segment(aes(x = 300, y = 500, xend = 415, yend = 20), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 300, y = 700, label = "max value= 415", size = 2.5) +
geom_segment(aes(x = -280, y = 500, xend = -380, yend = 20), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = -300, y = 700, label = "min value= -380", size = 2.5)
p1
# 4.99999 not 5 -- needed because of data imported from stata may be stored wierdly.
# pd1 <- subset(pd, abs(pd$diff) < 4.999999)
# Hmisc::describe(pd1$diff)
# plotting online-offline price differences (+-5 dollar price difference)
p2 <- ggplot(data = pd, aes(diff)) +
geom_histogram(
binwidth = 0.5, boundary = -0, closed = "left",
color = color.outline, fill = color[1], size = 0.25, alpha = 0.8, show.legend = F, na.rm = TRUE
) +
labs(x = "Online - offline price difference (US dollars)", y = "Frequency") +
theme_bg() +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(limits = c(-5, 5), breaks = seq(-5, 5, by = 1)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 5000), breaks = seq(0, 5000, by = 1000))
p2
p1 | p2
styler:::style_selection()
# CASE STUDY: Comparing Online and Offline Prices: Testing the Difference
t.test(pd$diff, mu = 0)
