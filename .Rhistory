scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 100)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.3), breaks = seq(0, 0.3, by = 0.1), labels = scales::percent_format()) +
theme_bg()
(p1 | p2)
# plotting same data using density plot
p3 <- ggplot(data = hotels_europe_london_viena, aes(x = price, y = stat(density), color = city)) +
geom_line(stat = "density", show.legend = F, na.rm = TRUE) +
labs(x = "Price (US dollars)", y = "Density", color = "") +
scale_color_manual(
name = "",
values = c(color[2], color[1]),
labels = c("London", "Vienna")
) +
scale_y_continuous(expand = c(0.0, 0.0), limits = c(0, 0.015), breaks = seq(0, 0.015, by = 0.003)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 100)) +
geom_text(aes(x = 340, y = 0.0026, label = "London"), color = color[2], size = 2.5) +
geom_text(aes(x = 170, y = 0.008, label = "Vienna"), color = color[1], size = 2.5) +
theme_bg()
p3
# summarizing all statistics in one table
hotels_europe_london_viena_tab <- hotels_europe_london_viena |>
dplyr::group_by(city) |>
dplyr::summarise(
n = length(price), mean = mean(price), median = median(price), min = min(price), max = max(price),
sd = sd(price), skew = ((mean(price) - median(price)) / sd(price))
)
hotels_europe_london_viena_tab
# CASE STUDY: Measuring Home Team Advantage in Football
# load data
games <- read_csv("input/epl_games.csv")
# looking at 2016/17 season only
games <- subset(games, season == 2016)
# adding a goal difference variable
games <- games |>
dplyr::mutate(home_goaladv = goals_home - goals_away)
# summary statistics
summary(games$home_goaladv)
psych::describe(games$home_goaladv)
# plotting the distribution of the goal difference variable
p1 <- ggplot(data = games, aes(x = home_goaladv, y = (..count..) / sum(..count..))) +
geom_histogram(
color = color.outline, fill = theme_colors[1],
size = 0.2, alpha = 0.8, show.legend = F, na.rm = TRUE,
binwidth = 1
) +
geom_text(stat = "count", aes(label = round((..count..) / sum(..count..) * 100, 1)), hjust = 0.5, vjust = -0.5, size = 2) +
labs(x = "Goal difference", y = "Share of games (percent)") +
scale_x_continuous(expand = c(0.05, 0.05), limits = c(-6, 6), breaks = seq(-6, 6, by = 1)) +
scale_y_continuous(expand = c(0, 0), limits = c(0, 0.25), breaks = seq(0, 0.25, by = 0.05), labels = scales::percent_format(accuracy = 5L)) +
theme_bg()
p1
reticulate::repl_python()
# CASE STUDY: Distributions of Body Height and Income
# load data
hrs <- read_csv("input/hrs_height_income.csv")
# parsing height var as numeric
hrs$height <- as.numeric(as.character(hrs$height))
# looking at the overall height distribution
Hmisc::describe(hrs$height)
# filtering height of women age 55-59
filtered_women_height <- hrs |>
dplyr::filter(age >= 55 & age < 60 & female == 1 & height > 1.3 & height < 2.1)
Hmisc::describe(filtered_women_height$height)
# plotting women height
p1 <- ggplot(filtered_women_height, aes(x = height)) +
geom_histogram(aes(y = ..density..),
binwidth = 0.025, boundary = min(filtered_women_height$height),
fill = color[1], color = color.outline, alpha = 0.8, closed = "left"
) +
stat_function(
fun = dnorm, colour = color[2],
args = with(filtered_women_height, c(mean = mean(height), sd = sd(height)))
) +
scale_y_continuous("Density",
position = "right", expand = c(0, 0), limits = c(0, 6),
sec.axis = sec_axis(~ . * 0.025, name = "Percent", breaks = seq(0, 0.15, by = 0.025), labels = percent_format(accuracy = 0.1))
) +
theme_bg() +
xlab("Height (meters)")
p1
# filtering income of women age 55-69
filtered_women_income <-  hrs  |>
dplyr::filter(age >= 55 & age < 60 & female == 1 & hhincome > 1 & hhincome < 1000)
Hmisc::describe(filtered_women_income$hhincome)
# plotting income histogram
p2 <- ggplot(filtered_women_income, aes(x = hhincome)) +
geom_histogram(aes(y = (..count..) / sum(..count..)),
binwidth = 20, boundary = 0, closed = "left",
fill = color[1], color = color.outline, alpha = 0.8
) +
ylab("Percent") +
xlab("Household income (thousand USD)") +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1000), breaks = seq(0, 1000, by = 100)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.3), breaks = seq(0, 0.3, by = 0.05), labels = scales::percent_format(accuracy = 1)) +
theme_bg()
p2
# log of household income
filtered_women_income <- filtered_women_income |>
dplyr::mutate(lnincome = log(hhincome))
# plotting log of household income
p3 <- ggplot(filtered_women_income, aes(x = lnincome)) +
geom_histogram(aes(y = ..density..),
binwidth = 0.25, boundary = 0, closed = "left",
fill = color[1], color = color.outline, alpha = 0.8
) +
stat_function(
fun = dnorm, colour = color[2],
args = with(filtered_women_income, c(mean = mean(lnincome), sd = sd(lnincome)))
) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 8), breaks = seq(0, 8, by = 1)) +
scale_y_continuous("Density",
position = "right", expand = c(0, 0), limits = c(0, 0.4),
sec.axis = sec_axis(~ . * 0.25,
name = "Percent", breaks = seq(0, 0.1, by = 0.025),
labels = percent_format(accuracy = 0.1)
)
) +
theme_bg() +
ylab("Percent") +
xlab("ln(household income, thousand USD)")
p3
# CASE STUDY: Management quality and firm size: describing patterns of association
# load data
wms <- read_csv("input/wms_da_textbook.csv")
# sample selection
wms <- wms |>
dplyr::filter(country=="Mexico" & wave==2013 & emp_firm>=100  & emp_firm<=5000)
# summary
summary(wms$emp_firm)
Hmisc::describe(wms$emp_firm)
wms  |>
dplyr::select(management, emp_firm)  |>
dplyr::summarise_all(tibble::lst(min, max, mean, median, sd, length))
# plotting distribution of the management score
p1 <- ggplot(data = wms, aes(x = management)) +
geom_histogram_da(binwidth = 0.25, type = "percent", boundary = 0) +
labs(x = "Management score", y = "Percent") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(1, 5)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.25), breaks = seq(0, 0.25, by = 0.05), labels = scales::percent_format(accuracy = 1)) +
theme_bg()
p1
# plotting the distribution of employees
p2 <- ggplot(data = wms, aes(x = emp_firm)) +
geom_histogram_da(binwidth = 200, type = "percent") +
labs(x = "Firm size (employment)", y = "Percent") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 5000), breaks = seq(0, 5000, by = 1000)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.3), breaks = seq(0, 0.3, by = 0.05), labels = scales::percent_format(accuracy = 1)) +
theme_bg()
p2
# creating variable log
wms$lnemp = log(wms$emp_firm)
Hmisc::describe(wms$lnemp)
# plotting the natural log of number of employees
p3 <- ggplot(data = wms, aes(x = lnemp)) +
geom_histogram_da(binwidth = 0.25, type = "percent", boundary = 0) +
labs(x = "Firm size (ln(employment))", y = "Percent") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(4, 9)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.2), breaks = seq(0, 0.2, by = 0.04), labels = scales::percent_format(accuracy = 1)) +
theme_bg()
p3
# CASE STUDY: Management quality and firm size: describing patterns of association
# generating employment bins
wms$emp3bins <- ifelse(wms$emp_firm < 200, 1,
ifelse(wms$emp_firm >= 200 & wms$emp_firm < 1000, 2,
ifelse(wms$emp_firm >= 1000, 3, 100)
)
)
Hmisc::describe(wms$emp3bins)
# converting created variable as factor
wms$emp3bins <- as.factor(wms$emp3bins)
# creating new wms for lean management
wms_lean <- wms |>
dplyr::select(emp3bins, lean1) |>
dplyr::group_by(emp3bins, lean1) |>
dplyr::summarise(Count = n()) |>
dplyr::mutate(Percent = round(Count / sum(Count), digits = 5)) |>
dplyr::ungroup() # use %>% ungroup() when do multiple times group_by
# plotting lean management
p1 <- ggplot(data = wms_lean, aes(x = emp3bins, y = Percent, fill = factor(lean1, levels = rev(unique(lean1))))) +
geom_bar(stat = "identity", position = "fill", width = 0.6, color = "white", size = 0.5, alpha = 0.8) +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1), breaks = seq(0, 1, by = 0.2), labels = scales::percent_format()) +
scale_x_discrete(labels = c("1" = "Small", "2" = "Medium", "3" = "Large")) +
scale_fill_manual(values = c(color[3], color[1], color[5], color[2], color[4]), name = NULL) +
labs(x = "Firm size (employment), 3 bins", y = "Percent", title = "Lean Management") +
theme_bg() +
theme(legend.position = "right")
p1
# creating new wms for performance tracking
wms_per <- wms |>
dplyr::select(emp3bins, perf2) |>
dplyr::group_by(emp3bins, perf2) |>
dplyr::summarise(Count = n()) |>
dplyr::mutate(Percent = round(Count / sum(Count), digits = 5)) |>
dplyr::ungroup()
# plotting performance tracking
p2 <- ggplot(data = wms_per, aes(x = emp3bins, y = Percent, fill = factor(perf2, levels = rev(unique(perf2))))) +
geom_bar(stat = "identity", position = "fill", width = 0.6, color = "white", size = 0.5, alpha = 0.8) +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1), breaks = seq(0, 1, by = 0.2), labels = scales::percent_format()) +
scale_x_discrete(labels = c("1" = "Small", "2" = "Medium", "3" = "Large")) +
scale_fill_manual(values = c(color[3], color[1], color[5], color[2], color[4]), name = NULL) +
labs(x = "Firm size (employment), 3 bins", y = "Percent", title = "Performance Tracking") +
theme_bg() +
theme(legend.position = "right")
p2
# CASE STUDY: Management quality and firm size: describing patterns of association
# re-coding employee bins
wms$emp3bins <- ifelse(wms$emp3bins == 1, 150,
ifelse(wms$emp3bins == 2, 600,
ifelse(wms$emp3bins == 3, 3000, NA)
)
)
# summary
wms  |>
dplyr::select(emp_firm, emp3bins)  |>
dplyr::group_by(emp3bins)  |>
dplyr::summarise_all(tibble::lst(min, max, mean, median, sd, length))
# generating variables by mean (3 bins)
wms_mean03 <- wms  |>
dplyr::group_by(emp3bins)  |>
dplyr::summarize(management_emp3bins = mean(management))
# plotting conditional mean (3 bins of employment)
p1 <- ggplot(data = wms_mean03, aes(x = emp3bins, y = management_emp3bins)) +
geom_point(size = 2, color = color[3], fill = color[1], shape = 21, alpha = 0.8, na.rm = T) +
scale_y_continuous(expand = c(0.01, 0.01), limits = c(2.4, 3.4), breaks = seq(2.4, 3.4, by = 0.2)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 3000), breaks = seq(0, 3000, by = 500)) +
labs(x = "Firm size (employment), 3 bins", y = "Management score") +
theme_bg()
p1
# generating employment bins of 10
wms$emp10bins <- wms$emp_firm  |>  ggplot2::cut_number(10)
# summary
wms_summary <- wms  |>
dplyr::select(emp_firm, emp10bins)  |>
dplyr::group_by(emp10bins)  |>
dplyr::summarise_all(tibble::lst(min, max, mean, median, sd, length))
wms_summary
# re-coding
levels(wms$emp10bins) <- wms_summary  |>
dplyr::pull(mean)  |>
round()
wms$emp10bins <- as.numeric(levels(wms$emp10bins))[wms$emp10bins]
# summary
wms  |>
dplyr::select(emp_firm, emp10bins)  |>
dplyr::group_by(emp10bins)  |>
dplyr::summarise_all(tibble::lst(min, max, mean, median, sd, length))
# generating variables by mean (10 bins)
wms_mean10 <- wms  |>
dplyr::group_by(emp10bins)  |>
dplyr::summarize(management_emp10bins = mean(management))
# plotting conditional mean (10 bins of employment)
p2 <- ggplot(data = wms_mean10, aes(x = emp10bins, y = management_emp10bins)) +
geom_point(size = 2, color = color[3], fill = color[1], shape = 21, alpha = 0.8, na.rm = T) +
scale_y_continuous(expand = c(0.01, 0.01), limits = c(2.5, 3.5), breaks = seq(2.5, 3.5, by = 0.25)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 3500), breaks = seq(0, 3500, by = 500)) +
labs(x = "Firm size (employment), 10 bins", y = "Management score") +
theme_bg()
p2
# this is a simpler solution, similar looking graph (not in book):
binsreg::binsreg(wms$management, wms$emp_firm, nbins = 3)
binsreg::binsreg(wms$management, wms$emp_firm, nbins = 10)
# plotting avg score by employment
p3 <- ggplot(data = wms, aes(x = emp_firm, y = management)) +
geom_point(color = color[1], size = 1.5, shape = 16, alpha = 0.8, show.legend = FALSE, na.rm = TRUE) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 5000), breaks = seq(0, 5000, by = 1000)) +
scale_y_continuous(expand = c(0.01, 0.01), limits = c(1, 5), breaks = seq(1, 5, 1)) +
labs(x = "Firm size (employment)", y = "Management score") +
theme_bg()
p3
# creating log var
wms$lnemp <-  log(wms$emp_firm)
# plotting avg score by employment (log)
p4 <- ggplot(data = wms, aes(x = lnemp, y = management)) +
geom_point(color = color[1], size = 1.5, shape = 16, alpha = 0.8, show.legend = FALSE, na.rm = TRUE) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(4, 9), breaks = seq(4, 9, by = 1)) +
scale_y_continuous(expand = c(0.01, 0.01), limits = c(1, 5), breaks = seq(1, 5, 1)) +
labs(x = "Firm size (ln(employment))", y = "Management score") +
theme_bg()
p4
# transforming as bin categories factor
wms$emp3bins <- as.factor(wms$emp3bins)
levels(wms$emp3bins) <- c("Small", "Medium", "Large")
# plotting boxplots
p5 <- ggplot(data = wms, aes(x = emp3bins, y = management)) +
stat_boxplot(aes(group = emp3bins), geom = "errorbar", width = 0.5, color = c(color[2], color[1], color[3]), size = 0.5, na.rm = T) +
geom_boxplot(aes(group = emp3bins), color = c(color[2], color[1], color[3]), fill = c(color[2], color[1], color[3]), size = 0.5, width = 0.5, alpha = 0.3, na.rm = T) +
labs(x = "Firm size (employment), 3 bins", y = "Management score") +
scale_y_continuous(expand = c(0.01, 0.01), limits = c(1, 5), breaks = seq(1, 5, 1)) +
theme_bg()
p5
# plotting violin plots
p6 <- ggplot(data = wms, aes(x = emp3bins, y = management, color = emp3bins, fill = emp3bins)) +
geom_violin(aes(group = emp3bins), size = 0.3, alpha = 0.3, trim = F, show.legend = F, na.rm = TRUE) +
geom_boxplot(aes(group = emp3bins), color = c(color[2], color[1], color[3]), fill = c(color[2], color[1], color[3]), size = 0.5, width = 0.2, alpha = 0.3, na.rm = T) +
labs(x = "Firm size (employment), 3 bins", y = "Management score") +
scale_y_continuous(expand = c(0.01, 0.01), limits = c(0, 6), breaks = seq(0, 6, 1)) +
scale_color_manual(
name = "",
values = c(color[2], color[1], color[3])
) +
scale_fill_manual(
name = "",
values = c(color[2], color[1], color[3])
) +
theme_bg()
p6
# CASE STUDY: Management quality and firm size: describing patterns of association
# calculating overall correlation coefficient
cor(wms$management, wms$emp_firm, use = "complete.obs")
# looking at the most recent industry code for the firms
table(wms$sic)
# recoding industry codes
wms$industry_broad[wms$sic <= 21] <- "food_drinks_tobacco"
wms$industry_broad[wms$sic >= 22 & wms$sic <= 23 | wms$sic == 31] <- "textile_apparel_leather_etc"
wms$industry_broad[wms$sic >= 24 & wms$sic <= 27] <- "wood_furniture_paper"
wms$industry_broad[wms$sic >= 28 & wms$sic <= 30] <- "chemicals_etc"
wms$industry_broad[wms$sic >= 32 & wms$sic < 35] <- "materials_metals"
wms$industry_broad[wms$sic >= 35 & wms$sic < 37] <- "electronics"
wms$industry_broad[wms$sic == 37] <- "auto"
wms$industry_broad[wms$sic >= 38] <- "other"
table(wms$industry_broad)
# summary management
wms  |>
dplyr::select(management, industry_broad)  |>
dplyr::filter(!is.na(industry_broad))  |>
dplyr::group_by(industry_broad)  |>
dplyr::summarise(
Min = min(management),
Max = max(management),
SD = sd(management),
Median = median(management),
n()
)
# summary employment
wms  |>
dplyr::select(emp_firm, industry_broad)  |>
dplyr::filter(!is.na(industry_broad))  |>
dplyr::group_by(industry_broad)  |>
dplyr::summarise(
Min = min(emp_firm),
Max = max(emp_firm),
SD = sd(emp_firm),
Median = median(emp_firm),
n()
)
# calculating correlation per industry broad
cor <- wms  |>
dplyr::group_by(industry_broad)  |>
dplyr::summarize(COR = cor(management, emp_firm))
# creating a table with the average of all relevant variables for the latent
wms_tab <- wms  |>
dplyr::select(emp_firm, industry_broad, management)  |>
dplyr::group_by(industry_broad)  |>
dplyr::summarise(Mean = mean(management), Obs = n())
# adding correlation to the table
wms_tab$cor <- cor$COR
# recoding variables
wms_tab$industry_broad <- wms_tab$industry_broad  |>  dplyr::recode(
auto = "Auto",
chemicals_etc = "Chemicals",
electronics = "Machinery, equipment, electronics",
food_drinks_tobacco = "Food, drinks, tobacco",
materials_metals = "Materials, metals",
textile_apparel_leather_etc = "Textile, apparel, leather",
wood_furniture_paper = "Wood, furniture, paper",
other = "Other"
)
# adding the last row with all category
last_row <- wms_tab  |>  dplyr::summarise(Mean = mean(Mean), Obs = sum(Obs), cor = mean(cor))
last_row$industry_broad <- "All"
wms_tab <- wms_tab  |>  dplyr::add_row(
industry_broad = last_row$industry_broad,
Mean = last_row$Mean,
cor = last_row$cor,
Obs = last_row$Obs
)
# formatting the table
wms_tab <- wms_tab  |>  dplyr::select(industry_broad, cor, Mean, Obs)
wms_tab
# CASE STUDY: What likelihood of loss to expect on a stock portfolio
# load data
sp500 <- read_csv("input/SP500_2006_16_data.csv", na = c("", "#N/A"))
# subsetting all the values that are NOT NAs
sp500 <- subset(sp500, VALUE != "NA")
# creating percent return
sp500 <- sp500 |>
dplyr::mutate(pct_return = (VALUE - dplyr::lag(VALUE)) / dplyr::lag(VALUE) * 100)
# creating date variable
sp500$year <- format(sp500$DATE, "%Y")
sp500$month <- format(sp500$DATE, "%m")
sp500$year <- as.numeric(sp500$year)
sp500$month <- as.numeric(sp500$month)
sp500$yearmonth <- sp500$year * 100 + sp500$month
# plotting daily returns
p1 <- ggplot(sp500, aes(pct_return)) +
geom_histogram_da(binwidth = 0.25, type = "frequency") +
geom_vline(xintercept = -5, size = 0.7, color = color[2]) +
labs(x = "Daily return (percent)", y = "Frequency") +
coord_cartesian(xlim = c(-10, 10), ylim = c(0, 400)) +
scale_y_continuous(expand = c(0, 0)) +
geom_segment(aes(x = -6, y = 220, xend = -5, yend = 220), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = -8, y = 220, label = "5% loss", size = 2.5) +
theme_bg()
p1
# Create 10 000 samples, with 500 and 1000 observations in each sample, taken from sp500
# remove first row as it has NA in pct_return
pct_return <- sp500  |>
dplyr::filter(!is.na(pct_return))  |>
dplyr::pull(pct_return)
# function for a specified number of samples: draws a specified number of observations from a vector, calculates the percentage of obs with greater than 5% losses
# 3 inputs: 'vector' is a vector of the source data, in this case pct_return. 'n_samples' is the number of samples we want to use.
# 'n_obs' is the number of observations in each sample
# output is a vector
create_samples <- function(vector, n_samples, n_obs) {
samples_pcloss <- c()
for (i in 1:n_samples) {
single_sample <- sample(vector, n_obs, replace = FALSE)
samples_pcloss[i] <- sum(single_sample < -5) / n_obs * 100
}
samples_pcloss
}
set.seed(123)
# creating samples
nobs_1000 <- create_samples(pct_return, 10000, 1000)
nobs_500 <- create_samples(pct_return, 10000, 500)
# converting results as tibble
nobs_df <- tibble(nobs_500,nobs_1000)
# calculating the se
se <- qnorm(0.95) * sd(nobs_df$nobs_1000) / sqrt(length(nobs_df$nobs_1000))
# calculating CI
left <- mean(nobs_df$nobs_1000) - se
right <- mean(nobs_df$nobs_1000) + se
# plotting simulated number of days with big losses
options(digits = 2)
p2 <- ggplot(nobs_df, aes(nobs_1000)) +
geom_histogram(binwidth = 0.1, color = color.outline, fill = color[1], alpha = 0.8, boundary = 0, closed = "left") +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
geom_vline(aes(xintercept = mean(nobs_1000)), color = color[2], size = 0.7) +
coord_cartesian(xlim = c(0, 1.5), ylim = c(0, 2500)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.5), breaks = seq(0, 1.5, by = 0.25)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 2500), breaks = seq(0, 2500, by = 500)) +
geom_segment(aes(x = 0.8, y = 2000, xend = 0.53, yend = 2000), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 0.85, y = 2000, label = "Mean", size = 2.5) +
theme_bg()
p2
# comparing density for both simulations
p3 <- ggplot(nobs_df, aes(nobs_1000)) +
stat_density(geom = "line", aes(color = "n1000"), bw = 0.45, size = 1, kernel = "epanechnikov") +
stat_density(geom = "line", aes(nobs_500, color = "n500"), bw = 0.45, linetype = "twodash", size = 1, kernel = "epanechnikov") +
labs(x = "Percent of days with losses over 5%", y = "Density") +
geom_vline(xintercept = 0.5, colour = color[3], size = 0.7, linetype = "dashed") +
geom_segment(aes(x = 0.9, y = 0.72, xend = 0.65, yend = 0.72), size = 0.5, arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 1.1, y = 0.72, label = "Larger sample", size = 2) +
geom_segment(aes(x = 0.9, y = 0.68, xend = 0.65, yend = 0.68), size = 0.5, arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 1.1, y = 0.68, label = "Smaller sample", size = 2) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.5), breaks = seq(0, 1.5, by = 0.25)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.8), breaks = seq(0, 0.8, by = 0.2)) +
scale_color_manual(name = "", values = c(n1000 = color[1], n500 = color[2])) +
theme_bg() +
theme(legend.position = "none")
p3
# plotting histogram of big loss simulations with N = 500 and N = 1000
p4 <- ggplot(data = nobs_df) +
geom_histogram(aes(x = nobs_500, y = (..count..) / sum(..count..) * 100, color = "n500", fill = "n500"), binwidth = 0.2, boundary = 0, closed = "left", alpha = 0.7) +
geom_histogram(aes(x = nobs_1000, y = (..count..) / sum(..count..) * 100, color = "n1000", fill = "n1000"), binwidth = 0.2, boundary = 0, closed = "left", alpha = 0.1, size = 0.7) +
ylab("Percent") +
xlab("Percent of days with losses over 5%") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.6), breaks = seq(0, 1.6, by = 0.2)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 50)) +
scale_color_manual(name = "", values = c(color[2], color[1])) +
scale_fill_manual(name = "", values = c(color[2], color[1])) +
theme_bg() +
theme(
legend.position = c(0.7, 0.9),
legend.key.size = unit(x = 0.4, units = "cm"),
legend.direction = "horizontal"
)
p4
# looking at distribution in a table
janitor::tabyl(nobs_df$nobs_500, sort = TRUE)
janitor::tabyl(nobs_df$nobs_1000, sort = TRUE)
set.seed(573164)
M <- 10000
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
Results <- as_tibble(Results)
names(Results) <- c(
"loss1", "loss2", "loss3", "loss4", "loss5", "loss6",
"loss7", "loss8", "loss9", "loss10"
)
p1 <- ggplot(Results, aes(loss5)) +
geom_histogram_da(type = "frequency", binwidth = 0.04, boundary = 0, closed = "left") +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1200), breaks = seq(0, 1200, 200)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.2), breaks = seq(0, 1.2, 0.1)) +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
theme_bg()
p1
# lintr::lint("main.Rmd", linters =
#               lintr::with_defaults(
#                 commented_code_linter = NULL,
#                 trailing_whitespace_linter = NULL
#                 )
#             )
# if you have additional scripts and want them to be linted too, add them here
# lintr::lint("scripts/my_script.R")
