dplyr::summarise(
Min = min(emp_firm),
Max = max(emp_firm),
SD = sd(emp_firm),
Median = median(emp_firm),
n()
)
# calculating correlation per industry broad
cor <- wms  |>
dplyr::group_by(industry_broad)  |>
dplyr::summarize(COR = cor(management, emp_firm))
# creating a table with the average of all relevant variables for the latent
wms_tab <- wms  |>
dplyr::select(emp_firm, industry_broad, management)  |>
dplyr::group_by(industry_broad)  |>
dplyr::summarise(Mean = mean(management), Obs = n())
# adding correlation to the table
wms_tab$cor <- cor$COR
# recoding variables
wms_tab$industry_broad <- wms_tab$industry_broad  |>  dplyr::recode(
auto = "Auto",
chemicals_etc = "Chemicals",
electronics = "Machinery, equipment, electronics",
food_drinks_tobacco = "Food, drinks, tobacco",
materials_metals = "Materials, metals",
textile_apparel_leather_etc = "Textile, apparel, leather",
wood_furniture_paper = "Wood, furniture, paper",
other = "Other"
)
# adding the last row with all category
last_row <- wms_tab  |>  dplyr::summarise(Mean = mean(Mean), Obs = sum(Obs), cor = mean(cor))
last_row$industry_broad <- "All"
wms_tab <- wms_tab  |>  dplyr::add_row(
industry_broad = last_row$industry_broad,
Mean = last_row$Mean,
cor = last_row$cor,
Obs = last_row$Obs
)
# formatting the table
wms_tab <- wms_tab  |>  dplyr::select(industry_broad, cor, Mean, Obs)
wms_tab
# CASE STUDY: What likelihood of loss to expect on a stock portfolio
# load data
sp500 <- read_csv("input/SP500_2006_16_data.csv", na = c("", "#N/A"))
# subsetting all the values that are NOT NAs
sp500 <- subset(sp500, VALUE != "NA")
# creating percent return
sp500 <- sp500 |>
dplyr::mutate(pct_return = (VALUE - dplyr::lag(VALUE)) / dplyr::lag(VALUE) * 100)
# creating date variable
sp500$year <- format(sp500$DATE, "%Y")
sp500$month <- format(sp500$DATE, "%m")
sp500$year <- as.numeric(sp500$year)
sp500$month <- as.numeric(sp500$month)
sp500$yearmonth <- sp500$year * 100 + sp500$month
# plotting daily returns
p1 <- ggplot(sp500, aes(pct_return)) +
geom_histogram_da(binwidth = 0.25, type = "frequency") +
geom_vline(xintercept = -5, size = 0.7, color = color[2]) +
labs(x = "Daily return (percent)", y = "Frequency") +
coord_cartesian(xlim = c(-10, 10), ylim = c(0, 400)) +
scale_y_continuous(expand = c(0, 0)) +
geom_segment(aes(x = -6, y = 220, xend = -5, yend = 220), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = -8, y = 220, label = "5% loss", size = 2.5) +
theme_bg()
p1
# Create 10 000 samples, with 500 and 1000 observations in each sample, taken from sp500
# remove first row as it has NA in pct_return
pct_return <- sp500  |>
dplyr::filter(!is.na(pct_return))  |>
dplyr::pull(pct_return)
# function for a specified number of samples: draws a specified number of observations from a vector, calculates the percentage of obs with greater than 5% losses
# 3 inputs: 'vector' is a vector of the source data, in this case pct_return. 'n_samples' is the number of samples we want to use.
# 'n_obs' is the number of observations in each sample
# output is a vector
create_samples <- function(vector, n_samples, n_obs) {
samples_pcloss <- c()
for (i in 1:n_samples) {
single_sample <- sample(vector, n_obs, replace = FALSE)
samples_pcloss[i] <- sum(single_sample < -5) / n_obs * 100
}
samples_pcloss
}
set.seed(123)
# creating samples
nobs_1000 <- create_samples(pct_return, 10000, 1000)
nobs_500 <- create_samples(pct_return, 10000, 500)
# converting results as tibble
nobs_df <- tibble(nobs_500,nobs_1000)
# calculating the se
se <- qnorm(0.95) * sd(nobs_df$nobs_1000) / sqrt(length(nobs_df$nobs_1000))
# calculating CI
left <- mean(nobs_df$nobs_1000) - se
right <- mean(nobs_df$nobs_1000) + se
# plotting simulated number of days with big losses
options(digits = 2)
p2 <- ggplot(nobs_df, aes(nobs_1000)) +
geom_histogram(binwidth = 0.1, color = color.outline, fill = color[1], alpha = 0.8, boundary = 0, closed = "left") +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
geom_vline(aes(xintercept = mean(nobs_1000)), color = color[2], size = 0.7) +
coord_cartesian(xlim = c(0, 1.5), ylim = c(0, 2500)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.5), breaks = seq(0, 1.5, by = 0.25)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 2500), breaks = seq(0, 2500, by = 500)) +
geom_segment(aes(x = 0.8, y = 2000, xend = 0.53, yend = 2000), arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 0.85, y = 2000, label = "Mean", size = 2.5) +
theme_bg()
p2
# comparing density for both simulations
p3 <- ggplot(nobs_df, aes(nobs_1000)) +
stat_density(geom = "line", aes(color = "n1000"), bw = 0.45, size = 1, kernel = "epanechnikov") +
stat_density(geom = "line", aes(nobs_500, color = "n500"), bw = 0.45, linetype = "twodash", size = 1, kernel = "epanechnikov") +
labs(x = "Percent of days with losses over 5%", y = "Density") +
geom_vline(xintercept = 0.5, colour = color[3], size = 0.7, linetype = "dashed") +
geom_segment(aes(x = 0.9, y = 0.72, xend = 0.65, yend = 0.72), size = 0.5, arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 1.1, y = 0.72, label = "Larger sample", size = 2) +
geom_segment(aes(x = 0.9, y = 0.68, xend = 0.65, yend = 0.68), size = 0.5, arrow = arrow(length = unit(0.1, "cm"))) +
annotate("text", x = 1.1, y = 0.68, label = "Smaller sample", size = 2) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.5), breaks = seq(0, 1.5, by = 0.25)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.8), breaks = seq(0, 0.8, by = 0.2)) +
scale_color_manual(name = "", values = c(n1000 = color[1], n500 = color[2])) +
theme_bg() +
theme(legend.position = "none")
p3
# plotting histogram of big loss simulations with N = 500 and N = 1000
p4 <- ggplot(data = nobs_df) +
geom_histogram(aes(x = nobs_500, y = (..count..) / sum(..count..) * 100, color = "n500", fill = "n500"), binwidth = 0.2, boundary = 0, closed = "left", alpha = 0.7) +
geom_histogram(aes(x = nobs_1000, y = (..count..) / sum(..count..) * 100, color = "n1000", fill = "n1000"), binwidth = 0.2, boundary = 0, closed = "left", alpha = 0.1, size = 0.7) +
ylab("Percent") +
xlab("Percent of days with losses over 5%") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.6), breaks = seq(0, 1.6, by = 0.2)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 50)) +
scale_color_manual(name = "", values = c(color[2], color[1])) +
scale_fill_manual(name = "", values = c(color[2], color[1])) +
theme_bg() +
theme(
legend.position = c(0.7, 0.9),
legend.key.size = unit(x = 0.4, units = "cm"),
legend.direction = "horizontal"
)
p4
# looking at distribution in a table
janitor::tabyl(nobs_df$nobs_500, sort = TRUE)
janitor::tabyl(nobs_df$nobs_1000, sort = TRUE)
set.seed(573164)
M <- 10000
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
Results <- as_tibble(Results)
names(Results) <- c(
"loss1", "loss2", "loss3", "loss4", "loss5", "loss6",
"loss7", "loss8", "loss9", "loss10"
)
p1 <- ggplot(Results, aes(loss5)) +
geom_histogram_da(type = "frequency", binwidth = 0.04, boundary = 0, closed = "left") +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1200), breaks = seq(0, 1200, 200)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.2), breaks = seq(0, 1.2, 0.1)) +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
theme_bg()
p1
fm <- function(sp500){
loss <- as.numeric(sp500$pct_return < (-5)) * 100
results <- mean(loss, na.rm = TRUE)
return(results)
}
set.seed(626)
bootmean <- boot(sp500, fm, R = 1000)
bootmean <- boot(sp500, fm, R = 10000)
fm <- function(sp500){
loss <- as.numeric(sp500$pct_return < (-5)) * 100
return(mean(loss, na.rm = TRUE))
}
set.seed(626)
bootmean <- boot(sp500, fm, R = 10000)
set.seed(573164)
M <- 10000
M
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
Results
dim(Results)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
# for (j in 1:10) {
#   loss <- as.numeric(bsample < (-j)) * 100
#   Results[i, j] <- mean(loss, na.rm = T)
# }
}
x <- for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
# for (j in 1:10) {
#   loss <- as.numeric(bsample < (-j)) * 100
#   Results[i, j] <- mean(loss, na.rm = T)
# }
}
x
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
Results <- as_tibble(Results)
View(Results)
View(Results)
View(Results)
View(Results)
set.seed(573164)
M <- 10000
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
Results <- as_tibble(Results)
names(Results) <- c(
"loss1", "loss2", "loss3", "loss4", "loss5", "loss6",
"loss7", "loss8", "loss9", "loss10"
)
p1 <- ggplot(Results, aes(loss5)) +
geom_histogram_da(type = "frequency", binwidth = 0.04, boundary = 0, closed = "left") +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1200), breaks = seq(0, 1200, 200)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.2), breaks = seq(0, 1.2, 0.1)) +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
theme_bg()
p1
View(Results)
set.seed(573164)
M <- 10000
Results <- matrix(rep(0, (M * 10)), nrow = M, ncol = 10)
for (i in 1:M) {
bsample <- sample(sp500$pct_return, size = dim(sp500)[1], replace = TRUE)
for (j in 1:10) {
loss <- as.numeric(bsample < (-j)) * 100
Results[i, j] <- mean(loss, na.rm = T)
}
}
Results <- as_tibble(Results)
names(Results) <- c(
"loss1", "loss2", "loss3", "loss4", "loss5", "loss6",
"loss7", "loss8", "loss9", "loss10"
)
p1 <- ggplot(Results, aes(loss5)) +
geom_histogram_da(type = "frequency", binwidth = 0.04, boundary = 0, closed = "left") +
scale_y_continuous(expand = c(0, 0), limits = c(0, 1200), breaks = seq(0, 1200, 200)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1.2), breaks = seq(0, 1.2, 0.1)) +
labs(x = "Percent of days with losses of 5% or more", y = "Frequency") +
theme_bg()
p1
# calculating the se
se <- qnorm(0.95) * sd(nobs_df$nobs_1000) / sqrt(length(nobs_df$nobs_1000))
se
sd
sd(sp500$pct_return)
sp500$pct_return
stderr(sp500$pct_return)
stderr(sp500)
stderr(sp500$pct_return > -0.5)
help("stderr")
psych::describe(sp500$pct_return)
psych::describe(sp500$pct_return > -0.5  )
psych::describe(sp500$pct_return > -5  )
help(psych::describe)
psych::describe(sp500$pct_return > -5, digits = 5)
psych::describe(sp500$pct_return > -5, digits = 2)
psych::describe(digits=2, sp500$pct_return > -5)
psych::describe(sp500$pct_return > -5)
# using the psych package
psych::describe(sp500$pct_return > -5, psych::digits = 2)
# using the psych package
psych::describe(sp500$pct_return > -5,
digits = 2)
# using the psych package
psych::describe(sp500$pct_return > -5)
styler:::style_selection()
# computation of the standard error of the mean
sem <- sd(sp500$pct_return > -5 / sqrt(length(sp500$pct_return > -5))
# computation of the standard error of the mean
sem <- sd(sp500$pct_return > -5 / sqrt(length(sp500$pct_return > -5))
# computation of the standard error of the mean
sem <- sd(sp500$pct_return > -5 / sqrt(length(sp500$pct_return > -5)))
sem
loss2 <- sp500$pct_return > -5
loss2
# computation of the standard error of the mean
loss2 <- sp500[, sp500$pct_return > -5]
# computation of the standard error of the mean
loss2 <- sp500 |>
dplyr::filter(pct_return > -5)
loss2
sem <- sd(loss2$pct_return / sqrt(length(loss2$pct_return)))
sem
# 95% confidence intervals of the mean
c(mean(loss2$pct_return) - 2 * sem, mean(loss2$pct_return) + 2 * sem)
sd(loss2$pct_return)
sem
# using the psych package
psych::describe(sp500$pct_return > -5)
# computation of the standard error of the mean
loss2 <- sp500 |>
dplyr::filter(pct_return > -5)
loss2
sem <- sd(loss2$pct_return / sqrt(length(loss2$pct_return)))
sem
# 95% confidence intervals of the mean
c(mean(loss2$pct_return) - 2 * sem, mean(loss2$pct_return) + 2 * sem)
# using the psych package
psych::describe(sp500$pct_return > -5)
# using the psych package
psych::describe(loss2$pct_return > -5)
# using the psych package
psych::describe(sp500$pct_return > -5)
loss2
# using the psych package
psych::describe(sp500$pct_return > -5)
sp500_loss <- sp500 |>
dplyr::filter(pct_return > -5)
sp500_loss
sp500
# using the psych package
psych::describe(sp500$pct_return)
> -5
# using the psych package
psych::describe(sp500$pct_return > -5)
sd(sp500$pct_return)
sd(p500$pct_return > -5)
sd(sp500$pct_return > -5)
sem <- sd(sp5002$pct_return / sqrt(length(sp500$pct_return)))
sem <- sd(sp500$pct_return / sqrt(length(sp500$pct_return)))
sem
# using the psych package
psych::describe(sp500$pct_return > -5)
x <- sqrt((1 / 2519))
x
x * 0.07
psych::describe(sp500$pct_return > -5)
# calculating the denomitar of the SEM formula = 0.02
x <- sqrt((1 / 2519))
# calculating the product of both operations -> 0.02 * 0.07
sem <- x * 0.07
sem
# calculating the CI
0.5 + 2 * 0.14
left <- 0.5 + 2 * 0.14
right <- 0.5 - 2 * 0.14
left
right
# computation of the standard error of the mean
# calculating the se
se <- qnorm(0.95) * sd(sp500$pct_return) / sqrt(length(sp500$pct_return))
left <- mean(sp500$pct_return) - se
right <- mean(sp500$pct_return) + se
se
left
# computation of the standard error of the mean
# calculating the se
se <- qnorm(0.95) * sd(list(sp500$pct_return)) / sqrt(length(list(sp500$pct_return)))
# using the psych package to figure out the sd = 0.07
psych::describe(sp500$pct_return > -5)
# calculating the denomitar of the SEM formula = 0.02
x <- sqrt((1 / 2519))
# calculating the product of both operations -> 0.02 * 0.07 = 0.0014 (0.14%) or the standard error of the mean
sem <- x * 0.07
sem
# calculating the 95% CI
left <- 0.5 + 2 * 0.14
right <- 0.5 - 2 * 0.14
left
right
sp500$pct_return
sd(sp500$pct_return, na.rm = T)
# computation of the standard error of the mean
# calculating the se
se <- qnorm(0.95) * sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(sp500$pct_return))
se
left <- mean(sp500$pct_return) - se
right <- mean(sp500$pct_return) +
left
left
left <- mean(sp500$pct_return) - se
right <- mean(sp500$pct_return) + se
left
right
left <- mean(sp500$pct_return, na.rm = TRUE) - se
right <- mean(sp500$pct_return, na.rm = TRUE) + se
left
right
se
# computation of the standard error of the mean
# calculating the se
se <- qnorm(0.95) * sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))
se
# computation of the standard error of the mean
# calculating the se
sem2 <- sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))
sem
sem2
styler:::style_selection()
# 95% confidence intervals of the mean
c(mean(sp500$pct_return, na.rm = TRUE) - 2 * sem2, mean(sp500$pct_return, na.rm = TRUE) + 2 * sem2)
sem
sem2
# using the psych package to figure out the sd = 0.07
psych::describe(sp500$pct_return > -5)
# computation of the standard error of the mean
# calculating the se
sem2 <- sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))
sem2
# computation of the standard error of the mean
# calculating the denominator of the SEM formula = 0.02
y <- (sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))) * sd(sp500$pct_return, na.rm = TRUE)
y
# computation of the standard error of the mean
# calculating the denominator of the SEM formula = 0.02
y <- sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))
y
y * 0.07
# computation of the standard error of the mean
# calculating the denominator of the SEM formula = 0.02
sem2 <- sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))
# 95% confidence intervals of the mean
ci <- c(mean(sp500$pct_return, na.rm = TRUE) - 2 * sem2, mean(sp500$pct_return, na.rm = TRUE) + 2 * sem2)
ci
left
right
# using the psych package to figure out the sd = 0.07
psych::describe(sp500$pct_return > -5)
# calculating the denominator of the SEM formula = 0.02
x <- sqrt((1 / 2519))
# calculating the product of both operations -> 0.02 * 0.07 = 0.0014 (0.14%) or the standard error of the mean
sem <- x * 0.07
sem
# calculating the 95% CI
left <- 0.5 + 2 * 0.14
right <- 0.5 - 2 * 0.14
left
right
# computation of the standard error of the mean
# calculating the denominator of the SEM formula = 0.02
sem2 <- sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))
#computation of the standard error of the mean
sem <- sd(x) / sqrt(length(x))
# 95% confidence intervals of the mean
ci <- c(mean(sp500$pct_return, na.rm = TRUE) - 2 * sem2, mean(sp500$pct_return, na.rm = TRUE) + 2 * sem2)
ci
psych::describe(sp500$pct_return > -5)
# calculating the denominator of the SEM formula = 0.02
x <- sqrt((1 / 2519))
# calculating the product of both operations -> 0.02 * 0.07 = 0.0014 (0.14%) or the standard error of the mean
sem <- x * 0.07
sem
# calculating the 95% CI
left <- 0.5 + 2 * 0.14
right <- 0.5 - 2 * 0.14
left
right
# computation of the standard error of the mean
# calculating the denominator of the SEM formula = 0.02
sem2 <- sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))
sem2
ci <- c(mean(sp500$pct_return, na.rm = TRUE) - 2 * sem2, mean(sp500$pct_return, na.rm = TRUE) + 2 * sem2)
ci
se <- qnorm(0.95) * sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(sp500$pct_return, na.rm = TRUE))
# calculating the se
se <- qnorm(0.95) * sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))
left <- mean(sp500$pct_return, na.rm = TRUE) - se
right <- mean(sp500$pct_return, na.rm = TRUE) + se
se <- qnorm(0.95) * sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))
# calculating CI
left2 <- mean(sp500$pct_return, na.rm = TRUE) - se
right2 <- mean(sp500$pct_return, na.rm = TRUE) + se
se
left2
right2
# calculating the se
se <- sd(sp500$pct_return, na.rm = TRUE) / sqrt(length(na.omit(sp500$pct_return)))
left2 <- mean(sp500$pct_return, na.rm = TRUE) - se
right2 <- mean(sp500$pct_return, na.rm = TRUE) + se
se
left2
right2
x
c(left, right)
psych::describe(sp500$pct_return > -5)
# calculating the denominator of the SEM formula = 0.02
x <- sqrt((1 / 2519))
# calculating the product of both operations -> 0.02 * 0.07 = 0.0014 (0.14%) or the standard error of the mean
sem <- x * 0.07
sem
# calculating the 95% CI
left <- 0.5 + 2 * 0.14
right <- 0.5 - 2 * 0.14
c(left, right)
# using the psych package to figure out the sd = 0.07
psych::describe(sp500$pct_return > -5)
# calculating the denominator of the SEM formula = 0.02
x <- sqrt((1 / 2519))
# calculating the product of both operations -> 0.02 * 0.07 = 0.0014 (0.14%) or the standard error of the mean
sem <- x * 0.07
sem
# calculating the 95% CI
right <- 0.5 + 2 * 0.14
left <- 0.5 - 2 * 0.14
c(left, right)
