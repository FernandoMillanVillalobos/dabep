}
detach_all_packages()
# this allows multiple persons to use the same RMarkdown
# without adjusting the working directory by themselves all the time
source("scripts/csf.R")
path_to_wd <- csf() # if this - for some reason - does not work,
# replace with a hardcoded path, like so: "~/projects/rddj-template/analysis/"
if (is.null(path_to_wd) | !dir.exists(path_to_wd)) {
print("WARNING: No working directory specified for current user")
} else {
setwd(path_to_wd)
}
# suppress scientific notation
options(scipen = 999)
# suppress summarise info
options(dplyr.summarise.inform = FALSE)
# unload global rstudioapi and knitr again to avoid conflicts with checkpoint
# this is only necessary if executed within RStudio
# outside of RStudio, namely in the knit.sh script, this causes RMarkdown
# rendering to fail, thus should not be executed there
if (Sys.getenv("RSTUDIO") == "1") {
detach_all_packages()
}
# from https://mran.revolutionanalytics.com/web/packages/\
# checkpoint/vignettes/using-checkpoint-with-knitr.html
# if you don't need a package, remove it from here (commenting not sufficient)
# tidyverse: see https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/
cat("
library(rstudioapi)
library(tidyverse, warn.conflicts = FALSE) # ggplot2, dplyr, tidyr, readr, purrr, tibble, magrittr, readxl
library(scales) # scales for ggplot2
library(jsonlite) # json
library(lintr) # code linting
library(sf)
library(rmarkdown)
library(data.table)
library(cowplot) # theme
library(extrafont)
library(waldo) # compare
library(psych) # some useful funs
library(ggrepel) # text labels
library(skimr)
library(haven)
library(Hmisc)
library(desc)
library(reshape2)
library(pastecs)
library(patchwork)
library(xtable)
library(reticulate)
library(janitor)", # names
file = "manifest.R"
)
# if checkpoint is not yet installed, install it (for people using this
# system for the first time)
if (!require(checkpoint)) {
if (!require(devtools)) {
install.packages("devtools", repos = "http://cran.us.r-project.org")
require(devtools)
}
devtools::install_github("RevolutionAnalytics/checkpoint",
ref = "v0.3.2", # could be adapted later,
# as of now (beginning of July 2017
# this is the current release on CRAN)
repos = "http://cran.us.r-project.org"
)
require(checkpoint)
}
# nolint start
if (!dir.exists("~/.checkpoint")) {
dir.create("~/.checkpoint")
}
# nolint end
# install packages for the specified CRAN snapshot date
checkpoint(
snapshot_date = package_date,
project = path_to_wd,
verbose = T,
scanForPackages = T,
use.knitr = F,
R.version = r_version
)
rm(package_date)
source("manifest.R")
unlink("manifest.R")
sessionInfo()
# if you want to outsource logic to other script files, see README for
# further information
# Load all visualizations functions as separate scripts
knitr::read_chunk("scripts/dviz.supp.R")
source("scripts/dviz.supp.R")
knitr::read_chunk("scripts/themes.R")
source("scripts/themes.R")
knitr::read_chunk("scripts/plot_grid.R")
source("scripts/plot_grid.R")
knitr::read_chunk("scripts/align_legend.R")
source("scripts/align_legend.R")
knitr::read_chunk("scripts/label_log10.R")
source("scripts/label_log10.R")
knitr::read_chunk("scripts/outliers.R")
source("scripts/outliers.R")
knitr::read_chunk("scripts/theme_bg.R")
source("scripts/theme_bg.R")
# load hotels_raw
hotels_raw <- read_csv("input/hotelbookingdata-vienna.csv")
# load hotels_clean
hotels_clean <- read_csv("input/hotels-vienna.csv")
# transform values of some variables (through splitting) into valid values
hotels_raw <- hotels_raw |>
tidyr::separate(center1distance, c("distance", NA), sep = " ") |>
tidyr::separate(center2distance, c("distance_alter", NA), sep = " ") |>
tidyr::separate(accommodationtype, c(NA, "accommodation_type"), sep = "@") |>
tidyr::separate(price_night, c(NA, NA, "nnight", NA), sep = " ") |>
tidyr::separate(guestreviewsrating, c("rating", NA), sep = " ")
head(hotels_raw)
# check: frequency table of all values incl. missing values
tab_rating <- hotels_raw |>
dplyr::group_by(rating) |>
dplyr::summarise(n = n()) |>
dplyr::mutate(
percent = round((n / sum(n)), 3),
cumpercent = round(cumsum(freq = n / sum(n)), 3)
)
tab_rating_reviewcount <- hotels_raw |>
dplyr::group_by(rating_reviewcount) |>
dplyr::summarise(n = n()) |>
dplyr::mutate(
percent = round((n / sum(n)), 3),
cumpercent = round(cumsum(freq = n / sum(n)), 3)
)
hotels_raw <- hotels_raw |>
dplyr::mutate(rating_count = as.numeric(rating_reviewcount))
Hmisc::describe(hotels_raw$rating_count)
# rename variables
hotels_raw <- hotels_raw |>
dplyr::rename(
ratingta = rating2_ta,
ratingta_count = rating2_ta_reviewcount,
country = addresscountryname,
city = s_city, stars = starrating
)
# check: key variables
tab_stars <- hotels_raw |>
dplyr::group_by(stars) |>
dplyr::summarise(n = n()) |>
dplyr::mutate(
percent = round((n / sum(n)), 3),
cumpercent = round(cumsum(freq = n / sum(n)), 3)
)
tab_rating <- hotels_raw |>
dplyr::group_by(rating) |>
dplyr::summarise(n = n()) |>
dplyr::mutate(
percent = round((n / sum(n)), 3),
cumpercent = round(cumsum(freq = n / sum(n)), 3)
)
# look for perfect duplicates
hotels_raw <- hotels_raw |>
dplyr::arrange(hotel_id)
# filtering duplicates rows by IDs and selecting key variables to check
hotels_raw |>
dplyr::group_by(hotel_id) |>
dplyr::filter(n() > 1) |>
dplyr::select(c(hotel_id, accommodation_type, price, distance, stars, rating, rating_count))
# getting rid of all duplicates (perfect duplicates)
hotels_raw <- hotels_raw |>
dplyr::distinct()
# handling missing values in text
# checking NAs values
summary(hotels_raw)
# making a summary of the missing values
summary_df <- t(stat.desc(hotels_raw))
summary_df
# creating a flag variable for missing values
hotels_raw <- hotels_raw |>
dplyr::mutate(misrating = ifelse(is.na(rating), 1, 0))
# counting all missing values
table(hotels_raw$misrating)
# looking missing values number per accomodation type
addmargins(table(hotels_raw$accommodation_type, hotels_raw$misrating))
# looking at the relation between missing values and price (mean)
hotels_raw |>
dplyr::group_by(accommodation_type, misrating) |>
dplyr::summarise(mean(price))
# spotting the exceptional case for "Hotels"
hotels_raw |>
dplyr::filter((misrating == 1) & (accommodation_type == "Hotel")) |>
dplyr::select(hotel_id, accommodation_type, price, distance, stars, rating, rating_count) |>
dplyr::slice(1)
# load data
games <- read_csv("input/epl_games.csv")
team_games <- read_csv("input/epl-teams-games.csv")
managers <- read_csv("input/football_managers.csv")
merged <- read_csv("input/football_managers_workfile.csv")
dplyr::glimpse(games)
dplyr::glimpse(team_games)
dplyr::glimpse(managers)
dplyr::glimpse(merged)
# look at basic data
games <- games |>
dplyr::arrange(team_home)
games <- games |>
dplyr::arrange(season, team_home)
games <- games |>
dplyr::filter(season == 2016)
# at team-game level
team_games <- team_games |>
dplyr::arrange(team)
team_games <- team_games |>
dplyr::arrange(season, team)
team_games <- team_games |>
dplyr::filter(season == 2016) |>
dplyr::arrange(date)
Hmisc::describe(merged$manager_id)
# arranging per season and team
merged <- merged |>
dplyr::arrange(season, team)
# considering average points per game as a measure of success
# 1. looking at the number of games managed per manager
games <- merged |>
dplyr::group_by(team, manager_id, manager_name) |>
dplyr::summarise(manager_games = n())
# 2. adding up the points earned over a career at a team (if manager worked for two teams, we consider it two cases)
points <- merged |>
dplyr::group_by(team, manager_id, manager_name) |>
dplyr::summarise(manager_points = sum(points))
# 3. once we have games and points, we divide total points by the number of games
avg_points <- merge(games, points, by = c("manager_id", "team", "manager_name")) |>
dplyr::group_by(team, manager_id, manager_name) |>
dplyr::mutate(manager_avg_points = (manager_points / manager_games)) |>
dplyr::arrange(manager_avg_points)
# 4. ranking the results
avg_points <- avg_points |>
dplyr::arrange(-manager_avg_points)
# 5. looking at those with at least 2 points per game
top_managers <- avg_points |>
dplyr::filter(manager_avg_points >= 2)
# 6. denoting caretakers (less than 18 games)
top_managers <- top_managers |>
dplyr::mutate(
manager_avg_points0 = ifelse(manager_games < 18, manager_avg_points, NA),
manager_avg_points1 = ifelse(manager_games > 18, manager_avg_points, NA)
)
# adding new variable for plotting
top_managers <- top_managers |>
dplyr::mutate(fill = case_when(
manager_games < 18 ~ "1",
manager_games > 18 ~ "0"
))
# plotting the results
p1 <- top_managers |>
ggplot(aes(x = reorder(manager_name, manager_avg_points), y = manager_avg_points, fill = fill, alpha = fill)) +
geom_col(show.legend = F) +
ylab("Average points per game") +
xlab("Manager name") +
scale_fill_manual(values = c(color[1], color[4])) +
scale_alpha_manual(values = c(0.8, 0.3)) +
scale_y_continuous(expand = c(0.01, 0.01), limits = c(0, 3), breaks = seq(0, 3, 0.3)) +
coord_flip() +
theme_bg() +
cowplot::background_grid(major = "x", minor = "none")
p1
# load data
vienna <- read_csv("input/hotels-vienna.csv")
# looking at the frequencies of all types of accommodation
table(vienna$accommodation_type)
# filtering accommodation: Hotel
vienna_hotels <- vienna |>
dplyr::filter(accommodation_type == "Hotel")
# plotting distributions
# Absolute frequency (count)
p1 <- ggplot(data = vienna_hotels, aes(x = stars)) +
geom_bar(color = color.outline, fill = color[1], alpha = 0.8, na.rm = T) +
geom_text(stat = "count", aes(label = ..count..), vjust = -0.5, size = 2.5) +
labs(x = "Star rating (N. stars)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0.5, 5.5), breaks = seq(1, 5, 0.5)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 140), breaks = seq(0, 140, 20)) +
theme_bg()
# Relative frequency (percent)
p2 <- ggplot(data = vienna_hotels, aes(x = stars, y = (..count..) / sum(..count..))) +
geom_bar(color = color.outline, fill = color[1], alpha = 0.8, na.rm = T) +
geom_text(stat = "count", aes(label = round((..count..) / sum(..count..) * 100, 1)), vjust = -0.5, size = 2.5) +
labs(x = "Star rating (N. stars)", y = "Percent") +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0.5, 5.5), breaks = seq(1, 5, 0.5)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.5), breaks = seq(0, 0.5, 0.1), labels = scales::percent_format(accuracy = 1)) +
theme_bg()
p1|p2
# filtering 3-4 stars, without 1000 euro extreme value
vienna_hotels <- vienna |>
dplyr::filter(accommodation_type == "Hotel") |>
dplyr::filter(stars >= 3 & stars <= 4) |>
dplyr::filter(!is.na(stars)) |>
dplyr::filter(price <= 1000)
table(vienna_hotels$city)
table(vienna_hotels$stars)
# plotting hotel price (different bindwidth)
p3 <- ggplot(data = vienna_hotels, aes(x = price)) +
geom_histogram_da(type = "frequency", binwidth = 10) +
labs(x = "Price (US dollars)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
coord_cartesian(clip = "off") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 50)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 40), breaks = seq(0, 40, by = 5)) +
theme_bg()
p4 <- ggplot(data = vienna_hotels, aes(x = price)) +
geom_histogram_da(type = "frequency", binwidth = 40) +
labs(x = "Price (US dollars)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
coord_cartesian(clip = "off") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 50)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 40), breaks = seq(0, 40, by = 5)) +
theme_bg()
p5 <- ggplot(data = vienna_hotels, aes(x = price)) +
geom_histogram_da(type = "frequency", binwidth = 80) +
labs(x = "Price (US dollars)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
coord_cartesian(clip = "off") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 50)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 40), breaks = seq(0, 40, by = 5)) +
theme_bg()
p6 <- ggplot(data = vienna_hotels, aes(x = price)) +
geom_histogram_da(type = "frequency", binwidth = 20) +
labs(x = "Price (US dollars)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
coord_cartesian(clip = "off") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 50)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 40), breaks = seq(0, 40, by = 5)) +
theme_bg()
(p3 | p4 | p5) / p6
# plotting distance
p7 <- ggplot(data = vienna_hotels, aes(x = distance)) +
geom_histogram_da(type = "frequency", binwidth = 0.5) +
labs(x = "Distance to city center (miles)", y = "Frequency") +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 14), breaks = seq(0, 14, by = 2)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 61), breaks = seq(0, 60, by = 10)) +
geom_segment(aes(x = 8.2, y = 0, xend = 8.2, yend = 60), color = color[2], size = 1) +
# geom_segment(aes(x = 10, y = 40, xend = 8.4, yend = 40), arrow = arrow(length = unit(0.2, "cm")))+
annotate("text", x = 11, y = 29, label = "Too far out", size = 2) +
annotate("rect", xmin = 8.2, xmax = 14, ymin = 0, ymax = 60, fill = color[4], alpha = 0.1) +
theme_bg()
p7
# looking at the actual place of hotels (included outside the city of Vienna)
table(vienna_hotels$city_actual)
# filtering 3-4 stars, less than 8miles from center, without 1000 euro extreme value
vienna_hotels <- vienna |>
dplyr::filter(accommodation_type == "Hotel") |>
dplyr::filter(stars >= 3 & stars <= 4) |>
dplyr::filter(!is.na(stars)) |>
dplyr::filter(price <= 1000) |>
dplyr::filter(city_actual == "Vienna")
# CASE STUDY: Comparing Hotel Prices in Europe: Vienna vs London
# load data
hotels_europe_price <- read_csv("input/hotels-europe_price.csv")
hotels_europe_features <- read_csv("input/hotels-europe_features.csv")
# creating a working data table for analysis
hotels_europe <- dplyr::left_join(hotels_europe_price, hotels_europe_features, by = "hotel_id")
# filtering for same Vienna data we used + London same date
hotels_europe_london_viena <- hotels_europe |>
dplyr::filter(year == 2017 & month == 11 & weekend == 0) |>
dplyr::filter(city %in% c("Vienna", "London")) |>
dplyr::filter(accommodation_type == "Hotel") |>
dplyr::filter(stars >= 3 & stars <= 4) |>
dplyr::filter(!is.na(stars)) |>
dplyr::filter(city_actual %in% c("Vienna", "London")) |>
dplyr::filter(price <= 600)
# looking at the mean price for both cities
hotels_europe_london_viena |>
dplyr::group_by(city) |>
dplyr::summarise(mean_price = mean(price), max = max(price), n = n())
# plotting the distribution of hotel price
p1 <- ggplot(data = filter(hotels_europe_london_viena, city == "Vienna"), aes(x = price)) +
geom_histogram_da(type = "percent", binwidth = 20) +
labs(x = "Price (US dollars)", y = "Percent", title = "Vienna") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 100)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.3), breaks = seq(0, 0.3, by = 0.1), labels = scales::percent_format()) +
theme_bg()
p2 <- ggplot(data = filter(hotels_europe_london_viena, city == "London"), aes(x = price)) +
geom_histogram_da(type = "percent", binwidth = 20) +
labs(x = "Price (US dollars)", y = "Percent", title = "London") +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 100)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.3), breaks = seq(0, 0.3, by = 0.1), labels = scales::percent_format()) +
theme_bg()
(p1 | p2)
# plotting same data using density plot
p3 <- ggplot(data = hotels_europe_london_viena, aes(x = price, y = stat(density), color = city)) +
geom_line(stat = "density", show.legend = F, na.rm = TRUE) +
labs(x = "Price (US dollars)", y = "Density", color = "") +
scale_color_manual(
name = "",
values = c(color[2], color[1]),
labels = c("London", "Vienna")
) +
scale_y_continuous(expand = c(0.0, 0.0), limits = c(0, 0.015), breaks = seq(0, 0.015, by = 0.003)) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 500), breaks = seq(0, 500, by = 100)) +
geom_text(aes(x = 340, y = 0.0026, label = "London"), color = color[2], size = 2.5) +
geom_text(aes(x = 170, y = 0.008, label = "Vienna"), color = color[1], size = 2.5) +
theme_bg()
p3
# summarizing all statistics in one table
hotels_europe_london_viena_tab <- hotels_europe_london_viena |>
dplyr::group_by(city) |>
dplyr::summarise(
n = length(price), mean = mean(price), median = median(price), min = min(price), max = max(price),
sd = sd(price), skew = ((mean(price) - median(price)) / sd(price))
)
hotels_europe_london_viena_tab
# CASE STUDY: Measuring Home Team Advantage in Football
# load data
games <- read_csv("input/epl_games.csv")
# looking at 2016/17 season only
games <- subset(games, season == 2016)
# adding a goal difference variable
games <- games |>
dplyr::mutate(home_goaladv = goals_home - goals_away)
# summary statistics
summary(games$home_goaladv)
psych::describe(games$home_goaladv)
# plotting the distribution of the goal difference variable
p1 <- ggplot(data = games, aes(x = home_goaladv, y = (..count..) / sum(..count..))) +
geom_histogram(
color = color.outline, fill = theme_colors[1],
size = 0.2, alpha = 0.8, show.legend = F, na.rm = TRUE,
binwidth = 1
) +
geom_text(stat = "count", aes(label = round((..count..) / sum(..count..) * 100, 1)), hjust = 0.5, vjust = -0.5, size = 2) +
labs(x = "Goal difference", y = "Share of games (percent)") +
scale_x_continuous(expand = c(0.05, 0.05), limits = c(-6, 6), breaks = seq(-6, 6, by = 1)) +
scale_y_continuous(expand = c(0, 0), limits = c(0, 0.25), breaks = seq(0, 0.25, by = 0.05), labels = scales::percent_format(accuracy = 5L)) +
theme_bg()
p1
reticulate::repl_python()
# CASE STUDY: Distributions of Body Height and Income
# load data
hrs <- read_csv("input/hrs_height_income.csv")
# parsing height var as numeric
hrs$height <- as.numeric(as.character(hrs$height))
# looking at the overall height distribution
Hmisc::describe(hrs$height)
# filtering height of women age 55-59
filtered_women_height <- hrs |>
dplyr::filter(age >= 55 & age < 60 & female == 1 & height > 1.3 & height < 2.1)
Hmisc::describe(filtered_women_height$height)
# plotting women height
p1 <- ggplot(filtered_women_height, aes(x = height)) +
geom_histogram(aes(y = ..density..),
binwidth = 0.025, boundary = min(filtered_women_height$height),
fill = color[1], color = color.outline, alpha = 0.8, closed = "left"
) +
stat_function(
fun = dnorm, colour = color[2],
args = with(filtered_women_height, c(mean = mean(height), sd = sd(height)))
) +
scale_y_continuous("Density",
position = "right", expand = c(0, 0), limits = c(0, 6),
sec.axis = sec_axis(~ . * 0.025, name = "Percent", breaks = seq(0, 0.15, by = 0.025), labels = percent_format(accuracy = 0.1))
) +
theme_bg() +
xlab("Height (meters)")
p1
# filtering income of women age 55-69
filtered_women_income <-  hrs  |>
dplyr::filter(age >= 55 & age < 60 & female == 1 & hhincome > 1 & hhincome < 1000)
Hmisc::describe(filtered_women_income$hhincome)
# plotting income histogram
p2 <- ggplot(filtered_women_income, aes(x = hhincome)) +
geom_histogram(aes(y = (..count..) / sum(..count..)),
binwidth = 20, boundary = 0, closed = "left",
fill = color[1], color = color.outline, alpha = 0.8
) +
ylab("Percent") +
xlab("Household income (thousand USD)") +
expand_limits(x = 0.01, y = 0.01) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 1000), breaks = seq(0, 1000, by = 100)) +
scale_y_continuous(expand = c(0.00, 0.00), limits = c(0, 0.3), breaks = seq(0, 0.3, by = 0.05), labels = scales::percent_format(accuracy = 1)) +
theme_bg()
p2
# log of household income
filtered_women_income <- filtered_women_income |>
dplyr::mutate(lnincome = log(hhincome))
# plotting log of household income
p3 <- ggplot(filtered_women_income, aes(x = lnincome)) +
geom_histogram(aes(y = ..density..),
binwidth = 0.25, boundary = 0, closed = "left",
fill = color[1], color = color.outline, alpha = 0.8
) +
stat_function(
fun = dnorm, colour = color[2],
args = with(filtered_women_income, c(mean = mean(lnincome), sd = sd(lnincome)))
) +
scale_x_continuous(expand = c(0.01, 0.01), limits = c(0, 8), breaks = seq(0, 8, by = 1)) +
scale_y_continuous("Density",
position = "right", expand = c(0, 0), limits = c(0, 0.4),
sec.axis = sec_axis(~ . * 0.25,
name = "Percent", breaks = seq(0, 0.1, by = 0.025),
labels = percent_format(accuracy = 0.1)
)
) +
theme_bg() +
ylab("Percent") +
xlab("ln(household income, thousand USD)")
p3
# lintr::lint("main.Rmd", linters =
#               lintr::with_defaults(
#                 commented_code_linter = NULL,
#                 trailing_whitespace_linter = NULL
#                 )
#             )
# if you have additional scripts and want them to be linted too, add them here
# lintr::lint("scripts/my_script.R")
